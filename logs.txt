
==> Audit <==
|-----------|----------------------------|----------|--------------------|---------|---------------------|---------------------|
|  Command  |            Args            | Profile  |        User        | Version |     Start Time      |      End Time       |
|-----------|----------------------------|----------|--------------------|---------|---------------------|---------------------|
| delete    |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 25 Jun 24 20:04 IST | 25 Jun 24 20:04 IST |
| start     | --driver=Hyper-V           | minikube | PRADEEP\ItsPradeep | v1.33.1 | 25 Jun 24 20:05 IST |                     |
| start     | --driver=docker            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 25 Jun 24 20:05 IST | 25 Jun 24 20:09 IST |
| dashboard |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 25 Jun 24 20:10 IST |                     |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:07 IST |                     |
| start     | --driver = docker          | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:08 IST |                     |
| dashboard |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:09 IST |                     |
| start     | --driver =docker           | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:10 IST |                     |
| start     | --driver=docker            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:10 IST |                     |
| start     | --driver=hyperv            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:11 IST |                     |
| start     | --driver = virtualbox      | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:12 IST |                     |
| start     | --driver = virtualbox      | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:13 IST |                     |
| start     | --driver=docker            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:14 IST |                     |
| start     | --vm-driver=docker --force | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:15 IST |                     |
| start     | --vm-driver=docker --force | minikube | PRADEEP\ItsPradeep | v1.33.1 | 04 Jul 24 23:18 IST | 04 Jul 24 23:19 IST |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 05 Jul 24 23:47 IST | 05 Jul 24 23:48 IST |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 00:02 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 00:03 IST |                     |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 18:15 IST | 06 Jul 24 18:15 IST |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 18:17 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 18:36 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 20:15 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 22:49 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 23:14 IST | 06 Jul 24 23:16 IST |
| delete    | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 23:17 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 23:20 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 23:23 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 23:57 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 06 Jul 24 23:59 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 09:43 IST |                     |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 16:45 IST | 07 Jul 24 16:46 IST |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 17:18 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 17:28 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 17:31 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 17:44 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 17:45 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 18:16 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 18:26 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 18:28 IST |                     |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 18:35 IST |                     |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 18:38 IST |                     |
| delete    |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 18:39 IST | 07 Jul 24 18:39 IST |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 18:43 IST |                     |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 20:57 IST |                     |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 20:58 IST |                     |
| delete    |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 20:58 IST | 07 Jul 24 20:59 IST |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 20:59 IST |                     |
| start     | --driver= docker           | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:00 IST |                     |
| delete    |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:00 IST | 07 Jul 24 21:00 IST |
| start     | --driver = docker          | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:01 IST |                     |
| start     | --driver docker            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:01 IST |                     |
| start     | --driver docker            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:07 IST |                     |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:09 IST |                     |
| start     | --driver = docker          | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:14 IST |                     |
| delete    |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:14 IST | 07 Jul 24 21:15 IST |
| start     | --driver = docker          | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:15 IST |                     |
| start     |                            | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:16 IST | 07 Jul 24 21:17 IST |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:18 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:19 IST |                     |
| service   | sketchboard-service        | minikube | PRADEEP\ItsPradeep | v1.33.1 | 07 Jul 24 21:19 IST |                     |
|-----------|----------------------------|----------|--------------------|---------|---------------------|---------------------|


==> Last Start <==
Log file created at: 2024/07/07 21:16:09
Running on machine: Pradeep
Binary: Built with gc go1.22.1 for windows/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0707 21:16:09.954106   15492 out.go:291] Setting OutFile to fd 96 ...
I0707 21:16:09.956831   15492 out.go:338] TERM=,COLORTERM=, which probably does not support color
I0707 21:16:09.956831   15492 out.go:304] Setting ErrFile to fd 100...
I0707 21:16:09.956831   15492 out.go:338] TERM=,COLORTERM=, which probably does not support color
I0707 21:16:09.990395   15492 out.go:298] Setting JSON to false
I0707 21:16:09.999416   15492 start.go:129] hostinfo: {"hostname":"Pradeep","uptime":624,"bootTime":1720366545,"procs":277,"os":"windows","platform":"Microsoft Windows 11 Home Single Language","platformFamily":"Standalone Workstation","platformVersion":"10.0.22631.3737 Build 22631.3737","kernelVersion":"10.0.22631.3737 Build 22631.3737","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"b265bfc8-d911-4481-bc75-be724c069c5f"}
W0707 21:16:09.999416   15492 start.go:137] gopshost.Virtualization returned error: not implemented yet
I0707 21:16:10.003066   15492 out.go:177] * minikube v1.33.1 on Microsoft Windows 11 Home Single Language 10.0.22631.3737 Build 22631.3737
I0707 21:16:10.008716   15492 notify.go:220] Checking for updates...
I0707 21:16:10.009282   15492 driver.go:392] Setting default libvirt URI to qemu:///system
I0707 21:16:10.010359   15492 global.go:112] Querying for installed drivers using PATH=C:\Python312\Scripts\;C:\Python312\;C:\Program Files (x86)\CambridgeSoft\ChemOffice2015\ChemScript\Lib;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files\Amazon\AWSCLIV2\;C:\Program Files\nodejs\;C:\Program Files\Git\cmd;C:\ProgramData\chocolatey\bin;;C:\Program Files\HP\HP One Agent;C:\Program Files\Docker\Docker\resources\bin;C:\Program Files\PuTTY\;C:\Users\upadh\AppData\Local\Microsoft\WindowsApps;C:\Users\upadh\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\upadh\AppData\Roaming\npm;C:\Users\upadh\Downloads\jdk-22_windows-x64_bin\jdk-22\bin;
I0707 21:16:10.060686   15492 virtualbox.go:136] virtual box version: 7.0.18r162988
I0707 21:16:10.060686   15492 global.go:133] virtualbox default: true priority: 6, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:7.0.18r162988
}
I0707 21:16:10.068700   15492 global.go:133] vmware default: false priority: 5, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "vmrun": executable file not found in %!P(MISSING)ATH%!R(MISSING)eason: Fix:Install vmrun Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/ Version:}
I0707 21:16:10.332863   15492 docker.go:122] docker version: linux-25.0.3:Docker Desktop 4.28.0 (139021)
I0707 21:16:10.338819   15492 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0707 21:16:11.284836   15492 info.go:266] docker info: {ID:51d7f176-c256-4a1d-8b45-f94ea2719631 Containers:2 ContainersRunning:0 ContainersPaused:0 ContainersStopped:2 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:45 OomKillDisable:true NGoroutines:76 SystemTime:2024-07-07 15:46:11.228869812 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:14 KernelVersion:5.15.146.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:12 MemTotal:3818905600 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:25.0.3 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:ae07eda36dd25f8a1b98dfbf587313b99c0190bb Expected:ae07eda36dd25f8a1b98dfbf587313b99c0190bb} RuncCommit:{ID:v1.1.12-0-g51d5e94 Expected:v1.1.12-0-g51d5e94} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.12.1-desktop.4] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.24.6-desktop.1] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container. Vendor:Docker Inc. Version:0.0.24] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.22] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.4] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.0.1] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.5.0]] Warnings:<nil>}}
I0707 21:16:11.285389   15492 global.go:133] docker default: true priority: 9, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0707 21:16:11.293849   15492 global.go:133] podman default: true priority: 3, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "podman": executable file not found in %!P(MISSING)ATH%!R(MISSING)eason: Fix:Install Podman Doc:https://minikube.sigs.k8s.io/docs/drivers/podman/ Version:}
I0707 21:16:11.293849   15492 global.go:133] ssh default: false priority: 4, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0707 21:16:12.655012   15492 global.go:133] hyperv default: true priority: 8, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0707 21:16:12.667341   15492 global.go:133] qemu2 default: true priority: 3, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "qemu-system-x86_64": executable file not found in %!P(MISSING)ATH%!R(MISSING)eason: Fix:Install qemu-system Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/qemu/ Version:}
I0707 21:16:12.667341   15492 driver.go:314] not recommending "ssh" due to default: false
I0707 21:16:12.667341   15492 driver.go:349] Picked: docker
I0707 21:16:12.667341   15492 driver.go:350] Alternatives: [hyperv virtualbox ssh]
I0707 21:16:12.667341   15492 driver.go:351] Rejects: [vmware podman qemu2]
I0707 21:16:12.673622   15492 out.go:177] * Automatically selected the docker driver. Other choices: hyperv, virtualbox, ssh
I0707 21:16:12.676940   15492 start.go:297] selected driver: docker
I0707 21:16:12.676940   15492 start.go:901] validating driver "docker" against <nil>
I0707 21:16:12.676940   15492 start.go:912] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0707 21:16:12.689219   15492 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0707 21:16:13.106147   15492 info.go:266] docker info: {ID:51d7f176-c256-4a1d-8b45-f94ea2719631 Containers:2 ContainersRunning:0 ContainersPaused:0 ContainersStopped:2 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:45 OomKillDisable:true NGoroutines:76 SystemTime:2024-07-07 15:46:13.0631749 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:14 KernelVersion:5.15.146.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:12 MemTotal:3818905600 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:25.0.3 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:ae07eda36dd25f8a1b98dfbf587313b99c0190bb Expected:ae07eda36dd25f8a1b98dfbf587313b99c0190bb} RuncCommit:{ID:v1.1.12-0-g51d5e94 Expected:v1.1.12-0-g51d5e94} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.12.1-desktop.4] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.24.6-desktop.1] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container. Vendor:Docker Inc. Version:0.0.24] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.22] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.4] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.0.1] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.5.0]] Warnings:<nil>}}
I0707 21:16:13.106680   15492 start_flags.go:310] no existing cluster config was found, will generate one from the flags 
I0707 21:16:13.165217   15492 start_flags.go:393] Using suggested 2200MB memory alloc based on sys=7502MB, container=3641MB
I0707 21:16:13.165742   15492 start_flags.go:929] Wait components to verify : map[apiserver:true system_pods:true]
I0707 21:16:13.169030   15492 out.go:177] * Using Docker Desktop driver with root privileges
I0707 21:16:13.172372   15492 cni.go:84] Creating CNI manager for ""
I0707 21:16:13.172372   15492 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0707 21:16:13.172372   15492 start_flags.go:319] Found "bridge CNI" CNI - setting NetworkPlugin=cni
I0707 21:16:13.172372   15492 start.go:340] cluster config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.30.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.30.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\upadh:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0707 21:16:13.176457   15492 out.go:177] * Starting "minikube" primary control-plane node in "minikube" cluster
I0707 21:16:13.180007   15492 cache.go:121] Beginning downloading kic base image for docker with docker
I0707 21:16:13.182884   15492 out.go:177] * Pulling base image v0.0.44 ...
I0707 21:16:13.188509   15492 preload.go:132] Checking if preload exists for k8s version v1.30.0 and runtime docker
I0707 21:16:13.188509   15492 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e in local docker daemon
I0707 21:16:13.188509   15492 preload.go:147] Found local preload: C:\Users\upadh\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.30.0-docker-overlay2-amd64.tar.lz4
I0707 21:16:13.188509   15492 cache.go:56] Caching tarball of preloaded images
I0707 21:16:13.188509   15492 preload.go:173] Found C:\Users\upadh\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.30.0-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0707 21:16:13.188509   15492 cache.go:59] Finished verifying existence of preloaded tar for v1.30.0 on docker
I0707 21:16:13.189865   15492 profile.go:143] Saving config to C:\Users\upadh\.minikube\profiles\minikube\config.json ...
I0707 21:16:13.189865   15492 lock.go:35] WriteFile acquiring C:\Users\upadh\.minikube\profiles\minikube\config.json: {Name:mk89773c68405ceebba5db294a07ea9041dc8dee Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0707 21:16:13.369253   15492 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e in local docker daemon, skipping pull
I0707 21:16:13.369253   15492 cache.go:144] gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e exists in daemon, skipping load
I0707 21:16:13.369950   15492 cache.go:194] Successfully downloaded all kic artifacts
I0707 21:16:13.370006   15492 start.go:360] acquireMachinesLock for minikube: {Name:mk48642207108ee0d8577b89e263600a147261e7 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0707 21:16:13.370581   15492 start.go:364] duration metric: took 510.8Âµs to acquireMachinesLock for "minikube"
I0707 21:16:13.370581   15492 start.go:93] Provisioning new machine with config: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.30.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.30.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\upadh:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} &{Name: IP: Port:8443 KubernetesVersion:v1.30.0 ContainerRuntime:docker ControlPlane:true Worker:true}
I0707 21:16:13.370581   15492 start.go:125] createHost starting for "" (driver="docker")
I0707 21:16:13.446288   15492 out.go:204] * Creating docker container (CPUs=2, Memory=2200MB) ...
I0707 21:16:13.447654   15492 start.go:159] libmachine.API.Create for "minikube" (driver="docker")
I0707 21:16:13.447654   15492 client.go:168] LocalClient.Create starting
I0707 21:16:13.448719   15492 main.go:141] libmachine: Reading certificate data from C:\Users\upadh\.minikube\certs\ca.pem
I0707 21:16:13.449885   15492 main.go:141] libmachine: Decoding PEM data...
I0707 21:16:13.449885   15492 main.go:141] libmachine: Parsing certificate...
I0707 21:16:13.451539   15492 main.go:141] libmachine: Reading certificate data from C:\Users\upadh\.minikube\certs\cert.pem
I0707 21:16:13.452159   15492 main.go:141] libmachine: Decoding PEM data...
I0707 21:16:13.452680   15492 main.go:141] libmachine: Parsing certificate...
I0707 21:16:13.461824   15492 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
W0707 21:16:13.618783   15492 cli_runner.go:211] docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}" returned with exit code 1
I0707 21:16:13.625058   15492 network_create.go:281] running [docker network inspect minikube] to gather additional debugging logs...
I0707 21:16:13.625058   15492 cli_runner.go:164] Run: docker network inspect minikube
W0707 21:16:13.774443   15492 cli_runner.go:211] docker network inspect minikube returned with exit code 1
I0707 21:16:13.774443   15492 network_create.go:284] error running [docker network inspect minikube]: docker network inspect minikube: exit status 1
stdout:
[]

stderr:
Error response from daemon: network minikube not found
I0707 21:16:13.774443   15492 network_create.go:286] output of [docker network inspect minikube]: -- stdout --
[]

-- /stdout --
** stderr ** 
Error response from daemon: network minikube not found

** /stderr **
I0707 21:16:13.779930   15492 cli_runner.go:164] Run: docker network inspect bridge --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0707 21:16:13.964640   15492 network.go:206] using free private subnet 192.168.49.0/24: &{IP:192.168.49.0 Netmask:255.255.255.0 Prefix:24 CIDR:192.168.49.0/24 Gateway:192.168.49.1 ClientMin:192.168.49.2 ClientMax:192.168.49.254 Broadcast:192.168.49.255 IsPrivate:true Interface:{IfaceName: IfaceIPv4: IfaceMTU:0 IfaceMAC:} reservation:0xc0014353e0}
I0707 21:16:13.965225   15492 network_create.go:124] attempt to create docker network minikube 192.168.49.0/24 with gateway 192.168.49.1 and MTU of 1500 ...
I0707 21:16:13.970186   15492 cli_runner.go:164] Run: docker network create --driver=bridge --subnet=192.168.49.0/24 --gateway=192.168.49.1 -o --ip-masq -o --icc -o com.docker.network.driver.mtu=1500 --label=created_by.minikube.sigs.k8s.io=true --label=name.minikube.sigs.k8s.io=minikube minikube
I0707 21:16:14.257720   15492 network_create.go:108] docker network minikube 192.168.49.0/24 created
I0707 21:16:14.258277   15492 kic.go:121] calculated static IP "192.168.49.2" for the "minikube" container
I0707 21:16:14.268094   15492 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I0707 21:16:14.447961   15492 cli_runner.go:164] Run: docker volume create minikube --label name.minikube.sigs.k8s.io=minikube --label created_by.minikube.sigs.k8s.io=true
I0707 21:16:14.643089   15492 oci.go:103] Successfully created a docker volume minikube
I0707 21:16:14.650935   15492 cli_runner.go:164] Run: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e -d /var/lib
I0707 21:16:17.266023   15492 cli_runner.go:217] Completed: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e -d /var/lib: (2.6150882s)
I0707 21:16:17.266023   15492 oci.go:107] Successfully prepared a docker volume minikube
I0707 21:16:17.266574   15492 preload.go:132] Checking if preload exists for k8s version v1.30.0 and runtime docker
I0707 21:16:17.266574   15492 kic.go:194] Starting extracting preloaded images to volume ...
I0707 21:16:17.272048   15492 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v C:\Users\upadh\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.30.0-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e -I lz4 -xf /preloaded.tar -C /extractDir
I0707 21:16:32.820569   15492 cli_runner.go:217] Completed: docker run --rm --entrypoint /usr/bin/tar -v C:\Users\upadh\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.30.0-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e -I lz4 -xf /preloaded.tar -C /extractDir: (15.5478735s)
I0707 21:16:32.820569   15492 kic.go:203] duration metric: took 15.5539951s to extract preloaded images to volume ...
I0707 21:16:32.827641   15492 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0707 21:16:33.371304   15492 info.go:266] docker info: {ID:51d7f176-c256-4a1d-8b45-f94ea2719631 Containers:2 ContainersRunning:0 ContainersPaused:0 ContainersStopped:2 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:46 OomKillDisable:true NGoroutines:76 SystemTime:2024-07-07 15:46:33.313834995 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:14 KernelVersion:5.15.146.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:12 MemTotal:3818905600 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:25.0.3 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:ae07eda36dd25f8a1b98dfbf587313b99c0190bb Expected:ae07eda36dd25f8a1b98dfbf587313b99c0190bb} RuncCommit:{ID:v1.1.12-0-g51d5e94 Expected:v1.1.12-0-g51d5e94} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.12.1-desktop.4] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.24.6-desktop.1] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container. Vendor:Docker Inc. Version:0.0.24] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.22] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.4] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.0.1] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.5.0]] Warnings:<nil>}}
I0707 21:16:33.380109   15492 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I0707 21:16:33.793889   15492 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube --name minikube --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube --network minikube --ip 192.168.49.2 --volume minikube:/var --security-opt apparmor=unconfined --memory=2200mb --memory-swap=2200mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e
I0707 21:16:34.724399   15492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Running}}
I0707 21:16:34.923491   15492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0707 21:16:35.123668   15492 cli_runner.go:164] Run: docker exec minikube stat /var/lib/dpkg/alternatives/iptables
I0707 21:16:35.379423   15492 oci.go:144] the created container "minikube" has a running status.
I0707 21:16:35.379974   15492 kic.go:225] Creating ssh key for kic: C:\Users\upadh\.minikube\machines\minikube\id_rsa...
I0707 21:16:35.851309   15492 kic_runner.go:191] docker (temp): C:\Users\upadh\.minikube\machines\minikube\id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I0707 21:16:36.102715   15492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0707 21:16:36.319565   15492 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I0707 21:16:36.319565   15492 kic_runner.go:114] Args: [docker exec --privileged minikube chown docker:docker /home/docker/.ssh/authorized_keys]
I0707 21:16:36.643411   15492 kic.go:265] ensuring only current user has permissions to key file located at : C:\Users\upadh\.minikube\machines\minikube\id_rsa...
I0707 21:16:37.227482   15492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0707 21:16:37.393274   15492 machine.go:94] provisionDockerMachine start ...
I0707 21:16:37.402183   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:37.597512   15492 main.go:141] libmachine: Using SSH client type: native
I0707 21:16:37.633906   15492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x125a3c0] 0x125cfa0 <nil>  [] 0s} 127.0.0.1 50905 <nil> <nil>}
I0707 21:16:37.633906   15492 main.go:141] libmachine: About to run SSH command:
hostname
I0707 21:16:37.857234   15492 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0707 21:16:37.860776   15492 ubuntu.go:169] provisioning hostname "minikube"
I0707 21:16:37.867512   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:38.049064   15492 main.go:141] libmachine: Using SSH client type: native
I0707 21:16:38.049611   15492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x125a3c0] 0x125cfa0 <nil>  [] 0s} 127.0.0.1 50905 <nil> <nil>}
I0707 21:16:38.049611   15492 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0707 21:16:38.298862   15492 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0707 21:16:38.310353   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:38.546699   15492 main.go:141] libmachine: Using SSH client type: native
I0707 21:16:38.547337   15492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x125a3c0] 0x125cfa0 <nil>  [] 0s} 127.0.0.1 50905 <nil> <nil>}
I0707 21:16:38.547337   15492 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0707 21:16:38.735094   15492 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0707 21:16:38.735684   15492 ubuntu.go:175] set auth options {CertDir:C:\Users\upadh\.minikube CaCertPath:C:\Users\upadh\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\upadh\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\upadh\.minikube\machines\server.pem ServerKeyPath:C:\Users\upadh\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\upadh\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\upadh\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\upadh\.minikube}
I0707 21:16:38.735684   15492 ubuntu.go:177] setting up certificates
I0707 21:16:38.735684   15492 provision.go:84] configureAuth start
I0707 21:16:38.742363   15492 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0707 21:16:38.915332   15492 provision.go:143] copyHostCerts
I0707 21:16:38.916611   15492 exec_runner.go:144] found C:\Users\upadh\.minikube/ca.pem, removing ...
I0707 21:16:38.916611   15492 exec_runner.go:203] rm: C:\Users\upadh\.minikube\ca.pem
I0707 21:16:38.916611   15492 exec_runner.go:151] cp: C:\Users\upadh\.minikube\certs\ca.pem --> C:\Users\upadh\.minikube/ca.pem (1090 bytes)
I0707 21:16:38.918392   15492 exec_runner.go:144] found C:\Users\upadh\.minikube/cert.pem, removing ...
I0707 21:16:38.918392   15492 exec_runner.go:203] rm: C:\Users\upadh\.minikube\cert.pem
I0707 21:16:38.918936   15492 exec_runner.go:151] cp: C:\Users\upadh\.minikube\certs\cert.pem --> C:\Users\upadh\.minikube/cert.pem (1131 bytes)
I0707 21:16:38.920301   15492 exec_runner.go:144] found C:\Users\upadh\.minikube/key.pem, removing ...
I0707 21:16:38.920301   15492 exec_runner.go:203] rm: C:\Users\upadh\.minikube\key.pem
I0707 21:16:38.920917   15492 exec_runner.go:151] cp: C:\Users\upadh\.minikube\certs\key.pem --> C:\Users\upadh\.minikube/key.pem (1675 bytes)
I0707 21:16:38.922768   15492 provision.go:117] generating server cert: C:\Users\upadh\.minikube\machines\server.pem ca-key=C:\Users\upadh\.minikube\certs\ca.pem private-key=C:\Users\upadh\.minikube\certs\ca-key.pem org=ItsPradeep.minikube san=[127.0.0.1 192.168.49.2 localhost minikube]
I0707 21:16:39.351592   15492 provision.go:177] copyRemoteCerts
I0707 21:16:39.355205   15492 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0707 21:16:39.367448   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:39.551017   15492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50905 SSHKeyPath:C:\Users\upadh\.minikube\machines\minikube\id_rsa Username:docker}
I0707 21:16:39.672814   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1090 bytes)
I0707 21:16:39.728025   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\machines\server.pem --> /etc/docker/server.pem (1192 bytes)
I0707 21:16:39.765150   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0707 21:16:39.804312   15492 provision.go:87] duration metric: took 1.0674037s to configureAuth
I0707 21:16:39.804312   15492 ubuntu.go:193] setting minikube options for container-runtime
I0707 21:16:39.805414   15492 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.30.0
I0707 21:16:39.811456   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:39.983207   15492 main.go:141] libmachine: Using SSH client type: native
I0707 21:16:39.983793   15492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x125a3c0] 0x125cfa0 <nil>  [] 0s} 127.0.0.1 50905 <nil> <nil>}
I0707 21:16:39.983793   15492 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0707 21:16:40.278529   15492 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0707 21:16:40.278529   15492 ubuntu.go:71] root file system type: overlay
I0707 21:16:40.279146   15492 provision.go:314] Updating docker unit: /lib/systemd/system/docker.service ...
I0707 21:16:40.284596   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:40.466732   15492 main.go:141] libmachine: Using SSH client type: native
I0707 21:16:40.467397   15492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x125a3c0] 0x125cfa0 <nil>  [] 0s} 127.0.0.1 50905 <nil> <nil>}
I0707 21:16:40.467397   15492 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0707 21:16:40.662319   15492 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0707 21:16:40.669737   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:40.836765   15492 main.go:141] libmachine: Using SSH client type: native
I0707 21:16:40.836765   15492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x125a3c0] 0x125cfa0 <nil>  [] 0s} 127.0.0.1 50905 <nil> <nil>}
I0707 21:16:40.837343   15492 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0707 21:16:42.469420   15492 main.go:141] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2024-04-30 11:46:26.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2024-07-07 15:46:40.650940456 +0000
@@ -1,46 +1,49 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target docker.socket firewalld.service containerd.service time-set.target
-Wants=network-online.target containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
+Wants=network-online.target
 Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutStartSec=0
-RestartSec=2
-Restart=always
+Restart=on-failure
 
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
+LimitNOFILE=infinity
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I0707 21:16:42.469420   15492 machine.go:97] duration metric: took 5.0761462s to provisionDockerMachine
I0707 21:16:42.469420   15492 client.go:171] duration metric: took 29.021766s to LocalClient.Create
I0707 21:16:42.469420   15492 start.go:167] duration metric: took 29.021766s to libmachine.API.Create "minikube"
I0707 21:16:42.470078   15492 start.go:293] postStartSetup for "minikube" (driver="docker")
I0707 21:16:42.470078   15492 start.go:322] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0707 21:16:42.477927   15492 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0707 21:16:42.482968   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:42.650858   15492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50905 SSHKeyPath:C:\Users\upadh\.minikube\machines\minikube\id_rsa Username:docker}
I0707 21:16:42.792588   15492 ssh_runner.go:195] Run: cat /etc/os-release
I0707 21:16:42.802000   15492 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0707 21:16:42.802534   15492 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0707 21:16:42.802534   15492 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0707 21:16:42.802534   15492 info.go:137] Remote host: Ubuntu 22.04.4 LTS
I0707 21:16:42.803214   15492 filesync.go:126] Scanning C:\Users\upadh\.minikube\addons for local assets ...
I0707 21:16:42.803214   15492 filesync.go:126] Scanning C:\Users\upadh\.minikube\files for local assets ...
I0707 21:16:42.803768   15492 start.go:296] duration metric: took 333.6904ms for postStartSetup
I0707 21:16:42.811979   15492 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0707 21:16:42.975202   15492 profile.go:143] Saving config to C:\Users\upadh\.minikube\profiles\minikube\config.json ...
I0707 21:16:42.984858   15492 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0707 21:16:42.990359   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:43.160180   15492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50905 SSHKeyPath:C:\Users\upadh\.minikube\machines\minikube\id_rsa Username:docker}
I0707 21:16:43.284968   15492 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0707 21:16:43.296131   15492 start.go:128] duration metric: took 29.9255502s to createHost
I0707 21:16:43.296131   15492 start.go:83] releasing machines lock for "minikube", held for 29.9255502s
I0707 21:16:43.302469   15492 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0707 21:16:43.486886   15492 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0707 21:16:43.498629   15492 ssh_runner.go:195] Run: cat /version.json
I0707 21:16:43.498629   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:43.506815   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:16:43.699535   15492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50905 SSHKeyPath:C:\Users\upadh\.minikube\machines\minikube\id_rsa Username:docker}
I0707 21:16:43.718707   15492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50905 SSHKeyPath:C:\Users\upadh\.minikube\machines\minikube\id_rsa Username:docker}
I0707 21:16:44.888597   15492 ssh_runner.go:235] Completed: cat /version.json: (1.3899677s)
I0707 21:16:44.888597   15492 ssh_runner.go:235] Completed: curl -sS -m 2 https://registry.k8s.io/: (1.4017102s)
I0707 21:16:44.898400   15492 ssh_runner.go:195] Run: systemctl --version
I0707 21:16:44.918979   15492 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0707 21:16:44.940529   15492 ssh_runner.go:195] Run: sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
W0707 21:16:44.965612   15492 start.go:438] unable to name loopback interface in configureRuntimes: unable to patch loopback cni config "/etc/cni/net.d/*loopback.conf*": sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;: Process exited with status 1
stdout:

stderr:
find: '\\etc\\cni\\net.d': No such file or directory
I0707 21:16:44.974743   15492 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0707 21:16:45.038599   15492 cni.go:262] disabled [/etc/cni/net.d/100-crio-bridge.conf, /etc/cni/net.d/87-podman-bridge.conflist] bridge cni config(s)
I0707 21:16:45.038599   15492 start.go:494] detecting cgroup driver to use...
I0707 21:16:45.038599   15492 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0707 21:16:45.041546   15492 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0707 21:16:45.078993   15492 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0707 21:16:45.106360   15492 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0707 21:16:45.126198   15492 containerd.go:146] configuring containerd to use "cgroupfs" as cgroup driver...
I0707 21:16:45.134684   15492 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0707 21:16:45.177944   15492 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0707 21:16:45.208373   15492 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0707 21:16:45.235225   15492 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0707 21:16:45.263172   15492 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0707 21:16:45.290293   15492 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0707 21:16:45.317723   15492 ssh_runner.go:195] Run: sh -c "sudo sed -i '/^ *enable_unprivileged_ports = .*/d' /etc/containerd/config.toml"
I0707 21:16:45.347544   15492 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)\[plugins."io.containerd.grpc.v1.cri"\]|&\n\1  enable_unprivileged_ports = true|' /etc/containerd/config.toml"
I0707 21:16:45.374852   15492 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0707 21:16:45.403010   15492 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0707 21:16:45.427743   15492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0707 21:16:45.574804   15492 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0707 21:16:45.744191   15492 start.go:494] detecting cgroup driver to use...
I0707 21:16:45.744191   15492 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0707 21:16:45.756792   15492 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0707 21:16:45.782269   15492 cruntime.go:279] skipping containerd shutdown because we are bound to it
I0707 21:16:45.791103   15492 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0707 21:16:45.819561   15492 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0707 21:16:45.877208   15492 ssh_runner.go:195] Run: which cri-dockerd
I0707 21:16:45.898876   15492 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0707 21:16:45.920145   15492 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0707 21:16:45.965752   15492 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0707 21:16:46.106803   15492 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0707 21:16:46.258781   15492 docker.go:574] configuring docker to use "cgroupfs" as cgroup driver...
I0707 21:16:46.259446   15492 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (130 bytes)
I0707 21:16:46.297266   15492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0707 21:16:46.596052   15492 ssh_runner.go:195] Run: sudo systemctl restart docker
I0707 21:16:47.271769   15492 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.socket
I0707 21:16:47.380453   15492 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0707 21:16:47.412723   15492 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0707 21:16:47.569659   15492 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0707 21:16:47.730336   15492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0707 21:16:47.887014   15492 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0707 21:16:47.925012   15492 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0707 21:16:47.955671   15492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0707 21:16:48.162558   15492 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.service
I0707 21:16:48.746812   15492 start.go:541] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0707 21:16:48.758805   15492 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0707 21:16:48.766834   15492 start.go:562] Will wait 60s for crictl version
I0707 21:16:48.774747   15492 ssh_runner.go:195] Run: which crictl
I0707 21:16:48.791989   15492 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0707 21:16:48.946515   15492 start.go:578] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  26.1.1
RuntimeApiVersion:  v1
I0707 21:16:48.952219   15492 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0707 21:16:49.017212   15492 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0707 21:16:49.071545   15492 out.go:204] * Preparing Kubernetes v1.30.0 on Docker 26.1.1 ...
I0707 21:16:49.077595   15492 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I0707 21:16:49.452631   15492 network.go:96] got host ip for mount in container by digging dns: 192.168.65.254
I0707 21:16:49.460358   15492 ssh_runner.go:195] Run: grep 192.168.65.254	host.minikube.internal$ /etc/hosts
I0707 21:16:49.469178   15492 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.254	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0707 21:16:49.497329   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0707 21:16:49.673671   15492 kubeadm.go:877] updating cluster {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.30.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.30.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\upadh:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} ...
I0707 21:16:49.674179   15492 preload.go:132] Checking if preload exists for k8s version v1.30.0 and runtime docker
I0707 21:16:49.680088   15492 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0707 21:16:49.720242   15492 docker.go:685] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.30.0
registry.k8s.io/kube-controller-manager:v1.30.0
registry.k8s.io/kube-scheduler:v1.30.0
registry.k8s.io/kube-proxy:v1.30.0
registry.k8s.io/etcd:3.5.12-0
registry.k8s.io/coredns/coredns:v1.11.1
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0707 21:16:49.720242   15492 docker.go:615] Images already preloaded, skipping extraction
I0707 21:16:49.727241   15492 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0707 21:16:49.757244   15492 docker.go:685] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.30.0
registry.k8s.io/kube-scheduler:v1.30.0
registry.k8s.io/kube-controller-manager:v1.30.0
registry.k8s.io/kube-proxy:v1.30.0
registry.k8s.io/etcd:3.5.12-0
registry.k8s.io/coredns/coredns:v1.11.1
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0707 21:16:49.757783   15492 cache_images.go:84] Images are preloaded, skipping loading
I0707 21:16:49.758332   15492 kubeadm.go:928] updating node { 192.168.49.2 8443 v1.30.0 docker true true} ...
I0707 21:16:49.760032   15492 kubeadm.go:940] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.30.0/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.30.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:}
I0707 21:16:49.765183   15492 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0707 21:16:50.499321   15492 cni.go:84] Creating CNI manager for ""
I0707 21:16:50.499376   15492 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0707 21:16:50.499913   15492 kubeadm.go:84] Using pod CIDR: 10.244.0.0/16
I0707 21:16:50.499913   15492 kubeadm.go:181] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.30.0 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[containerRuntimeEndpoint:unix:///var/run/cri-dockerd.sock hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0707 21:16:50.499913   15492 kubeadm.go:187] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.30.0
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
containerRuntimeEndpoint: unix:///var/run/cri-dockerd.sock
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0707 21:16:50.507929   15492 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.30.0
I0707 21:16:50.533863   15492 binaries.go:44] Found k8s binaries, skipping transfer
I0707 21:16:50.541932   15492 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0707 21:16:50.557442   15492 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (307 bytes)
I0707 21:16:50.586915   15492 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0707 21:16:50.614802   15492 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2150 bytes)
I0707 21:16:50.656739   15492 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0707 21:16:50.664897   15492 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0707 21:16:50.695602   15492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0707 21:16:50.836264   15492 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0707 21:16:50.922406   15492 certs.go:68] Setting up C:\Users\upadh\.minikube\profiles\minikube for IP: 192.168.49.2
I0707 21:16:50.922406   15492 certs.go:194] generating shared ca certs ...
I0707 21:16:50.922406   15492 certs.go:226] acquiring lock for ca certs: {Name:mkd28156076e517da9b6b8fa51f556eb34e619e0 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0707 21:16:50.922406   15492 certs.go:235] skipping valid "minikubeCA" ca cert: C:\Users\upadh\.minikube\ca.key
I0707 21:16:50.925198   15492 certs.go:235] skipping valid "proxyClientCA" ca cert: C:\Users\upadh\.minikube\proxy-client-ca.key
I0707 21:16:50.925198   15492 certs.go:256] generating profile certs ...
I0707 21:16:50.925198   15492 certs.go:363] generating signed profile cert for "minikube-user": C:\Users\upadh\.minikube\profiles\minikube\client.key
I0707 21:16:50.926623   15492 crypto.go:68] Generating cert C:\Users\upadh\.minikube\profiles\minikube\client.crt with IP's: []
I0707 21:16:51.043978   15492 crypto.go:156] Writing cert to C:\Users\upadh\.minikube\profiles\minikube\client.crt ...
I0707 21:16:51.043978   15492 lock.go:35] WriteFile acquiring C:\Users\upadh\.minikube\profiles\minikube\client.crt: {Name:mke67e5f326bc084d6e14151fff79c59a9731521 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0707 21:16:51.043978   15492 crypto.go:164] Writing key to C:\Users\upadh\.minikube\profiles\minikube\client.key ...
I0707 21:16:51.043978   15492 lock.go:35] WriteFile acquiring C:\Users\upadh\.minikube\profiles\minikube\client.key: {Name:mke41b9824301d656cd73e196998ede463b29cd6 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0707 21:16:51.043978   15492 certs.go:363] generating signed profile cert for "minikube": C:\Users\upadh\.minikube\profiles\minikube\apiserver.key.7fb57e3c
I0707 21:16:51.043978   15492 crypto.go:68] Generating cert C:\Users\upadh\.minikube\profiles\minikube\apiserver.crt.7fb57e3c with IP's: [10.96.0.1 127.0.0.1 10.0.0.1 192.168.49.2]
I0707 21:16:51.287226   15492 crypto.go:156] Writing cert to C:\Users\upadh\.minikube\profiles\minikube\apiserver.crt.7fb57e3c ...
I0707 21:16:51.287226   15492 lock.go:35] WriteFile acquiring C:\Users\upadh\.minikube\profiles\minikube\apiserver.crt.7fb57e3c: {Name:mk6e3af66419f7526b40e2d39532ddc933ef01c2 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0707 21:16:51.287226   15492 crypto.go:164] Writing key to C:\Users\upadh\.minikube\profiles\minikube\apiserver.key.7fb57e3c ...
I0707 21:16:51.287226   15492 lock.go:35] WriteFile acquiring C:\Users\upadh\.minikube\profiles\minikube\apiserver.key.7fb57e3c: {Name:mka234ffba9d0fdddcf4afaab453d9f84fa04a01 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0707 21:16:51.287226   15492 certs.go:381] copying C:\Users\upadh\.minikube\profiles\minikube\apiserver.crt.7fb57e3c -> C:\Users\upadh\.minikube\profiles\minikube\apiserver.crt
I0707 21:16:51.358721   15492 certs.go:385] copying C:\Users\upadh\.minikube\profiles\minikube\apiserver.key.7fb57e3c -> C:\Users\upadh\.minikube\profiles\minikube\apiserver.key
I0707 21:16:51.358721   15492 certs.go:363] generating signed profile cert for "aggregator": C:\Users\upadh\.minikube\profiles\minikube\proxy-client.key
I0707 21:16:51.358721   15492 crypto.go:68] Generating cert C:\Users\upadh\.minikube\profiles\minikube\proxy-client.crt with IP's: []
I0707 21:16:51.452979   15492 crypto.go:156] Writing cert to C:\Users\upadh\.minikube\profiles\minikube\proxy-client.crt ...
I0707 21:16:51.452979   15492 lock.go:35] WriteFile acquiring C:\Users\upadh\.minikube\profiles\minikube\proxy-client.crt: {Name:mkc88d285cab57ccb109e20ddfc10ea3c2b88542 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0707 21:16:51.452979   15492 crypto.go:164] Writing key to C:\Users\upadh\.minikube\profiles\minikube\proxy-client.key ...
I0707 21:16:51.452979   15492 lock.go:35] WriteFile acquiring C:\Users\upadh\.minikube\profiles\minikube\proxy-client.key: {Name:mkae0df3042468ef88be14fe6e64df1cb19d7954 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0707 21:16:51.472493   15492 certs.go:484] found cert: C:\Users\upadh\.minikube\certs\ca-key.pem (1679 bytes)
I0707 21:16:51.474528   15492 certs.go:484] found cert: C:\Users\upadh\.minikube\certs\ca.pem (1090 bytes)
I0707 21:16:51.474528   15492 certs.go:484] found cert: C:\Users\upadh\.minikube\certs\cert.pem (1131 bytes)
I0707 21:16:51.474528   15492 certs.go:484] found cert: C:\Users\upadh\.minikube\certs\key.pem (1675 bytes)
I0707 21:16:51.481014   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0707 21:16:51.518166   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0707 21:16:51.555626   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0707 21:16:51.596060   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0707 21:16:51.634375   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\profiles\minikube\apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1411 bytes)
I0707 21:16:51.674028   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\profiles\minikube\apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I0707 21:16:51.711979   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\profiles\minikube\proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0707 21:16:51.748437   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\profiles\minikube\proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I0707 21:16:51.786076   15492 ssh_runner.go:362] scp C:\Users\upadh\.minikube\ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0707 21:16:51.829135   15492 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0707 21:16:51.935068   15492 ssh_runner.go:195] Run: openssl version
I0707 21:16:51.972466   15492 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0707 21:16:52.000005   15492 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0707 21:16:52.008711   15492 certs.go:528] hashing: -rw-r--r-- 1 root root 1111 Jun 25 14:39 /usr/share/ca-certificates/minikubeCA.pem
I0707 21:16:52.016668   15492 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0707 21:16:52.037121   15492 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0707 21:16:52.060170   15492 ssh_runner.go:195] Run: stat /var/lib/minikube/certs/apiserver-kubelet-client.crt
I0707 21:16:52.068975   15492 certs.go:399] 'apiserver-kubelet-client' cert doesn't exist, likely first start: stat /var/lib/minikube/certs/apiserver-kubelet-client.crt: Process exited with status 1
stdout:

stderr:
stat: cannot statx '/var/lib/minikube/certs/apiserver-kubelet-client.crt': No such file or directory
I0707 21:16:52.069491   15492 kubeadm.go:391] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.44@sha256:eb04641328b06c5c4a14f4348470e1046bbcf9c2cbc551486e343d3a49db557e Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.30.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.30.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\upadh:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0707 21:16:52.074525   15492 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0707 21:16:52.114297   15492 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0707 21:16:52.136427   15492 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0707 21:16:52.203244   15492 kubeadm.go:213] ignoring SystemVerification for kubeadm because of docker driver
I0707 21:16:52.206015   15492 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0707 21:16:52.227034   15492 kubeadm.go:154] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0707 21:16:52.227034   15492 kubeadm.go:156] found existing configuration files:

I0707 21:16:52.234527   15492 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I0707 21:16:52.250292   15492 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/admin.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/admin.conf: No such file or directory
I0707 21:16:52.257638   15492 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/admin.conf
I0707 21:16:52.281764   15492 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I0707 21:16:52.298629   15492 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/kubelet.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/kubelet.conf: No such file or directory
I0707 21:16:52.306490   15492 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/kubelet.conf
I0707 21:16:52.330150   15492 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I0707 21:16:52.345772   15492 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/controller-manager.conf: No such file or directory
I0707 21:16:52.354457   15492 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I0707 21:16:52.376933   15492 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I0707 21:16:52.392515   15492 kubeadm.go:162] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/scheduler.conf: No such file or directory
I0707 21:16:52.399694   15492 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I0707 21:16:52.414679   15492 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.30.0:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0707 21:16:52.836064   15492 kubeadm.go:309] 	[WARNING Swap]: swap is supported for cgroup v2 only; the NodeSwap feature gate of the kubelet is beta but disabled by default
I0707 21:16:52.975498   15492 kubeadm.go:309] 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0707 21:17:12.752357   15492 kubeadm.go:309] [init] Using Kubernetes version: v1.30.0
I0707 21:17:12.752357   15492 kubeadm.go:309] [preflight] Running pre-flight checks
I0707 21:17:12.752357   15492 kubeadm.go:309] [preflight] Pulling images required for setting up a Kubernetes cluster
I0707 21:17:12.752910   15492 kubeadm.go:309] [preflight] This might take a minute or two, depending on the speed of your internet connection
I0707 21:17:12.752910   15492 kubeadm.go:309] [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
I0707 21:17:12.752910   15492 kubeadm.go:309] [certs] Using certificateDir folder "/var/lib/minikube/certs"
I0707 21:17:12.757415   15492 out.go:204]   - Generating certificates and keys ...
I0707 21:17:12.758032   15492 kubeadm.go:309] [certs] Using existing ca certificate authority
I0707 21:17:12.758032   15492 kubeadm.go:309] [certs] Using existing apiserver certificate and key on disk
I0707 21:17:12.758544   15492 kubeadm.go:309] [certs] Generating "apiserver-kubelet-client" certificate and key
I0707 21:17:12.758544   15492 kubeadm.go:309] [certs] Generating "front-proxy-ca" certificate and key
I0707 21:17:12.758544   15492 kubeadm.go:309] [certs] Generating "front-proxy-client" certificate and key
I0707 21:17:12.758544   15492 kubeadm.go:309] [certs] Generating "etcd/ca" certificate and key
I0707 21:17:12.758544   15492 kubeadm.go:309] [certs] Generating "etcd/server" certificate and key
I0707 21:17:12.759106   15492 kubeadm.go:309] [certs] etcd/server serving cert is signed for DNS names [localhost minikube] and IPs [192.168.49.2 127.0.0.1 ::1]
I0707 21:17:12.759106   15492 kubeadm.go:309] [certs] Generating "etcd/peer" certificate and key
I0707 21:17:12.759106   15492 kubeadm.go:309] [certs] etcd/peer serving cert is signed for DNS names [localhost minikube] and IPs [192.168.49.2 127.0.0.1 ::1]
I0707 21:17:12.759106   15492 kubeadm.go:309] [certs] Generating "etcd/healthcheck-client" certificate and key
I0707 21:17:12.759666   15492 kubeadm.go:309] [certs] Generating "apiserver-etcd-client" certificate and key
I0707 21:17:12.759666   15492 kubeadm.go:309] [certs] Generating "sa" key and public key
I0707 21:17:12.759666   15492 kubeadm.go:309] [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
I0707 21:17:12.759666   15492 kubeadm.go:309] [kubeconfig] Writing "admin.conf" kubeconfig file
I0707 21:17:12.759666   15492 kubeadm.go:309] [kubeconfig] Writing "super-admin.conf" kubeconfig file
I0707 21:17:12.760223   15492 kubeadm.go:309] [kubeconfig] Writing "kubelet.conf" kubeconfig file
I0707 21:17:12.760223   15492 kubeadm.go:309] [kubeconfig] Writing "controller-manager.conf" kubeconfig file
I0707 21:17:12.760223   15492 kubeadm.go:309] [kubeconfig] Writing "scheduler.conf" kubeconfig file
I0707 21:17:12.760778   15492 kubeadm.go:309] [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
I0707 21:17:12.760829   15492 kubeadm.go:309] [control-plane] Using manifest folder "/etc/kubernetes/manifests"
I0707 21:17:12.763013   15492 out.go:204]   - Booting up control plane ...
I0707 21:17:12.763561   15492 kubeadm.go:309] [control-plane] Creating static Pod manifest for "kube-apiserver"
I0707 21:17:12.764120   15492 kubeadm.go:309] [control-plane] Creating static Pod manifest for "kube-controller-manager"
I0707 21:17:12.764120   15492 kubeadm.go:309] [control-plane] Creating static Pod manifest for "kube-scheduler"
I0707 21:17:12.764120   15492 kubeadm.go:309] [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
I0707 21:17:12.764679   15492 kubeadm.go:309] [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I0707 21:17:12.764679   15492 kubeadm.go:309] [kubelet-start] Starting the kubelet
I0707 21:17:12.765261   15492 kubeadm.go:309] [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests"
I0707 21:17:12.765261   15492 kubeadm.go:309] [kubelet-check] Waiting for a healthy kubelet. This can take up to 4m0s
I0707 21:17:12.765261   15492 kubeadm.go:309] [kubelet-check] The kubelet is healthy after 1.503265409s
I0707 21:17:12.765772   15492 kubeadm.go:309] [api-check] Waiting for a healthy API server. This can take up to 4m0s
I0707 21:17:12.765772   15492 kubeadm.go:309] [api-check] The API server is healthy after 13.00253404s
I0707 21:17:12.765772   15492 kubeadm.go:309] [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
I0707 21:17:12.766319   15492 kubeadm.go:309] [kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the configuration for the kubelets in the cluster
I0707 21:17:12.766319   15492 kubeadm.go:309] [upload-certs] Skipping phase. Please see --upload-certs
I0707 21:17:12.766846   15492 kubeadm.go:309] [mark-control-plane] Marking the node minikube as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
I0707 21:17:12.766846   15492 kubeadm.go:309] [bootstrap-token] Using token: k7defo.tla0qfci5o6k6dj2
I0707 21:17:12.769595   15492 out.go:204]   - Configuring RBAC rules ...
I0707 21:17:12.770134   15492 kubeadm.go:309] [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
I0707 21:17:12.770134   15492 kubeadm.go:309] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
I0707 21:17:12.770664   15492 kubeadm.go:309] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
I0707 21:17:12.771234   15492 kubeadm.go:309] [bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
I0707 21:17:12.771234   15492 kubeadm.go:309] [bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
I0707 21:17:12.771234   15492 kubeadm.go:309] [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
I0707 21:17:12.771783   15492 kubeadm.go:309] [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
I0707 21:17:12.771783   15492 kubeadm.go:309] [addons] Applied essential addon: CoreDNS
I0707 21:17:12.772324   15492 kubeadm.go:309] [addons] Applied essential addon: kube-proxy
I0707 21:17:12.772324   15492 kubeadm.go:309] 
I0707 21:17:12.772324   15492 kubeadm.go:309] Your Kubernetes control-plane has initialized successfully!
I0707 21:17:12.772324   15492 kubeadm.go:309] 
I0707 21:17:12.772324   15492 kubeadm.go:309] To start using your cluster, you need to run the following as a regular user:
I0707 21:17:12.772324   15492 kubeadm.go:309] 
I0707 21:17:12.772881   15492 kubeadm.go:309]   mkdir -p $HOME/.kube
I0707 21:17:12.772881   15492 kubeadm.go:309]   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
I0707 21:17:12.772881   15492 kubeadm.go:309]   sudo chown $(id -u):$(id -g) $HOME/.kube/config
I0707 21:17:12.772881   15492 kubeadm.go:309] 
I0707 21:17:12.772881   15492 kubeadm.go:309] Alternatively, if you are the root user, you can run:
I0707 21:17:12.772881   15492 kubeadm.go:309] 
I0707 21:17:12.773433   15492 kubeadm.go:309]   export KUBECONFIG=/etc/kubernetes/admin.conf
I0707 21:17:12.773433   15492 kubeadm.go:309] 
I0707 21:17:12.773433   15492 kubeadm.go:309] You should now deploy a pod network to the cluster.
I0707 21:17:12.773982   15492 kubeadm.go:309] Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
I0707 21:17:12.773982   15492 kubeadm.go:309]   https://kubernetes.io/docs/concepts/cluster-administration/addons/
I0707 21:17:12.773982   15492 kubeadm.go:309] 
I0707 21:17:12.774532   15492 kubeadm.go:309] You can now join any number of control-plane nodes by copying certificate authorities
I0707 21:17:12.774532   15492 kubeadm.go:309] and service account keys on each node and then running the following as root:
I0707 21:17:12.774532   15492 kubeadm.go:309] 
I0707 21:17:12.774532   15492 kubeadm.go:309]   kubeadm join control-plane.minikube.internal:8443 --token k7defo.tla0qfci5o6k6dj2 \
I0707 21:17:12.775074   15492 kubeadm.go:309] 	--discovery-token-ca-cert-hash sha256:e01b4977349f17ab05fe3f67e7fa9d3c0b24b45b56b505886637aaa13436349d \
I0707 21:17:12.775074   15492 kubeadm.go:309] 	--control-plane 
I0707 21:17:12.775074   15492 kubeadm.go:309] 
I0707 21:17:12.775074   15492 kubeadm.go:309] Then you can join any number of worker nodes by running the following on each as root:
I0707 21:17:12.775617   15492 kubeadm.go:309] 
I0707 21:17:12.775617   15492 kubeadm.go:309] kubeadm join control-plane.minikube.internal:8443 --token k7defo.tla0qfci5o6k6dj2 \
I0707 21:17:12.775617   15492 kubeadm.go:309] 	--discovery-token-ca-cert-hash sha256:e01b4977349f17ab05fe3f67e7fa9d3c0b24b45b56b505886637aaa13436349d 
I0707 21:17:12.776156   15492 cni.go:84] Creating CNI manager for ""
I0707 21:17:12.776156   15492 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0707 21:17:12.778474   15492 out.go:177] * Configuring bridge CNI (Container Networking Interface) ...
I0707 21:17:12.788019   15492 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0707 21:17:12.929754   15492 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (496 bytes)
I0707 21:17:12.971495   15492 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0707 21:17:12.985649   15492 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.30.0/kubectl --kubeconfig=/var/lib/minikube/kubeconfig label --overwrite nodes minikube minikube.k8s.io/updated_at=2024_07_07T21_17_12_0700 minikube.k8s.io/version=v1.33.1 minikube.k8s.io/commit=5883c09216182566a63dff4c326a6fc9ed2982ff minikube.k8s.io/name=minikube minikube.k8s.io/primary=true
I0707 21:17:12.985649   15492 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.30.0/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I0707 21:17:13.048742   15492 ops.go:34] apiserver oom_adj: -16
I0707 21:17:13.832089   15492 kubeadm.go:1107] duration metric: took 858.8737ms to wait for elevateKubeSystemPrivileges
W0707 21:17:13.855548   15492 kubeadm.go:286] apiserver tunnel failed: apiserver port not set
I0707 21:17:13.855548   15492 kubeadm.go:393] duration metric: took 21.7860568s to StartCluster
I0707 21:17:13.856133   15492 settings.go:142] acquiring lock: {Name:mk5f45580b55bb48d4687eb830c40862d4688f31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0707 21:17:13.856133   15492 settings.go:150] Updating kubeconfig:  C:\Users\upadh\.kube\config
I0707 21:17:13.860640   15492 lock.go:35] WriteFile acquiring C:\Users\upadh\.kube\config: {Name:mk23dc79cb0848c55a5f970f8496051ce013aa50 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0707 21:17:13.862355   15492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.30.0/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0707 21:17:13.863441   15492 start.go:234] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.30.0 ContainerRuntime:docker ControlPlane:true Worker:true}
I0707 21:17:13.866446   15492 out.go:177] * Verifying Kubernetes components...
I0707 21:17:13.863498   15492 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.30.0
I0707 21:17:13.868673   15492 addons.go:502] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volumesnapshots:false yakd:false]
I0707 21:17:13.872516   15492 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0707 21:17:13.873343   15492 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0707 21:17:13.873627   15492 addons.go:234] Setting addon storage-provisioner=true in "minikube"
I0707 21:17:13.874279   15492 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0707 21:17:13.874398   15492 host.go:66] Checking if "minikube" exists ...
I0707 21:17:13.886862   15492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0707 21:17:13.895056   15492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0707 21:17:13.896114   15492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0707 21:17:14.208684   15492 out.go:177]   - Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0707 21:17:14.212685   15492 addons.go:426] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0707 21:17:14.212685   15492 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0707 21:17:14.231880   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:17:14.275979   15492 addons.go:234] Setting addon default-storageclass=true in "minikube"
I0707 21:17:14.275979   15492 host.go:66] Checking if "minikube" exists ...
I0707 21:17:14.289252   15492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0707 21:17:14.446500   15492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.30.0/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed -e '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.65.254 host.minikube.internal\n           fallthrough\n        }' -e '/^        errors *$/i \        log' | sudo /var/lib/minikube/binaries/v1.30.0/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I0707 21:17:14.469051   15492 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0707 21:17:14.515301   15492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50905 SSHKeyPath:C:\Users\upadh\.minikube\machines\minikube\id_rsa Username:docker}
I0707 21:17:14.549745   15492 addons.go:426] installing /etc/kubernetes/addons/storageclass.yaml
I0707 21:17:14.549745   15492 ssh_runner.go:362] scp storageclass/storageclass.yaml --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0707 21:17:14.558922   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0707 21:17:14.761217   15492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50905 SSHKeyPath:C:\Users\upadh\.minikube\machines\minikube\id_rsa Username:docker}
I0707 21:17:14.944328   15492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.30.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0707 21:17:15.273505   15492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.30.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0707 21:17:16.134943   15492 ssh_runner.go:235] Completed: sudo systemctl start kubelet: (1.6653809s)
I0707 21:17:16.134943   15492 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.30.0/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed -e '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.65.254 host.minikube.internal\n           fallthrough\n        }' -e '/^        errors *$/i \        log' | sudo /var/lib/minikube/binaries/v1.30.0/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -": (1.6884437s)
I0707 21:17:16.135507   15492 start.go:946] {"host.minikube.internal": 192.168.65.254} host record injected into CoreDNS's ConfigMap
I0707 21:17:16.142916   15492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0707 21:17:16.366733   15492 api_server.go:52] waiting for apiserver process to appear ...
I0707 21:17:16.375912   15492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0707 21:17:16.628716   15492 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.30.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: (1.684388s)
I0707 21:17:16.628716   15492 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.30.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: (1.3552109s)
I0707 21:17:16.628716   15492 api_server.go:72] duration metric: took 2.7652179s to wait for apiserver process to appear ...
I0707 21:17:16.629260   15492 api_server.go:88] waiting for apiserver healthz status ...
I0707 21:17:16.629260   15492 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:50904/healthz ...
I0707 21:17:16.646781   15492 api_server.go:279] https://127.0.0.1:50904/healthz returned 200:
ok
I0707 21:17:16.651845   15492 api_server.go:141] control plane version: v1.30.0
I0707 21:17:16.651845   15492 api_server.go:131] duration metric: took 22.5849ms to wait for apiserver health ...
I0707 21:17:16.656332   15492 out.go:177] * Enabled addons: storage-provisioner, default-storageclass
I0707 21:17:16.656935   15492 system_pods.go:43] waiting for kube-system pods to appear ...
I0707 21:17:16.661020   15492 addons.go:505] duration metric: took 2.7981497s for enable addons: enabled=[storage-provisioner default-storageclass]
I0707 21:17:16.657459   15492 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I0707 21:17:16.678614   15492 system_pods.go:59] 5 kube-system pods found
I0707 21:17:16.679268   15492 system_pods.go:61] "etcd-minikube" [d59d0264-d56f-4449-af26-290012453b5e] Running
I0707 21:17:16.679268   15492 system_pods.go:61] "kube-apiserver-minikube" [d2136b84-b905-4b01-ab35-a9ad7623c402] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0707 21:17:16.679268   15492 system_pods.go:61] "kube-controller-manager-minikube" [79b15926-f84f-4f75-98e2-c36954c02d3c] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0707 21:17:16.679268   15492 system_pods.go:61] "kube-scheduler-minikube" [ffeba112-e684-4c78-a07b-c139a34ccbcb] Running
I0707 21:17:16.679268   15492 system_pods.go:61] "storage-provisioner" [aa4600a6-7b3a-4b0a-9fcd-6b5f9a791af2] Pending: PodScheduled:Unschedulable (0/1 nodes are available: 1 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.)
I0707 21:17:16.679268   15492 system_pods.go:74] duration metric: took 18.2485ms to wait for pod list to return data ...
I0707 21:17:16.679268   15492 kubeadm.go:576] duration metric: took 2.8157704s to wait for: map[apiserver:true system_pods:true]
I0707 21:17:16.679268   15492 node_conditions.go:102] verifying NodePressure condition ...
I0707 21:17:16.686606   15492 node_conditions.go:122] node storage ephemeral capacity is 1055762868Ki
I0707 21:17:16.686606   15492 node_conditions.go:123] node cpu capacity is 12
I0707 21:17:16.687209   15492 node_conditions.go:105] duration metric: took 7.9409ms to run NodePressure ...
I0707 21:17:16.687209   15492 start.go:240] waiting for startup goroutines ...
I0707 21:17:16.687209   15492 start.go:245] waiting for cluster config update ...
I0707 21:17:16.687209   15492 start.go:254] writing updated cluster config ...
I0707 21:17:16.695945   15492 ssh_runner.go:195] Run: rm -f paused
I0707 21:17:17.302459   15492 start.go:600] kubectl: 1.30.2, cluster: 1.30.0 (minor skew: 0)
I0707 21:17:17.305172   15492 out.go:177] * Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default


==> Docker <==
Jul 07 15:46:46 minikube dockerd[1009]: time="2024-07-07T15:46:46.233344728Z" level=warning msg="WARNING: No blkio throttle.write_iops_device support"
Jul 07 15:46:46 minikube dockerd[1009]: time="2024-07-07T15:46:46.233369526Z" level=info msg="Docker daemon" commit=ac2de55 containerd-snapshotter=false storage-driver=overlay2 version=26.1.1
Jul 07 15:46:46 minikube dockerd[1009]: time="2024-07-07T15:46:46.233418452Z" level=info msg="Daemon has completed initialization"
Jul 07 15:46:46 minikube dockerd[1009]: time="2024-07-07T15:46:46.302359433Z" level=info msg="API listen on /var/run/docker.sock"
Jul 07 15:46:46 minikube dockerd[1009]: time="2024-07-07T15:46:46.302395291Z" level=info msg="API listen on [::]:2376"
Jul 07 15:46:46 minikube systemd[1]: Started Docker Application Container Engine.
Jul 07 15:46:46 minikube systemd[1]: Stopping Docker Application Container Engine...
Jul 07 15:46:46 minikube dockerd[1009]: time="2024-07-07T15:46:46.608398715Z" level=info msg="Processing signal 'terminated'"
Jul 07 15:46:46 minikube dockerd[1009]: time="2024-07-07T15:46:46.611516287Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Jul 07 15:46:46 minikube dockerd[1009]: time="2024-07-07T15:46:46.613163600Z" level=info msg="Daemon shutdown complete"
Jul 07 15:46:46 minikube dockerd[1009]: time="2024-07-07T15:46:46.613404618Z" level=info msg="stopping event stream following graceful shutdown" error="context canceled" module=libcontainerd namespace=plugins.moby
Jul 07 15:46:46 minikube systemd[1]: docker.service: Deactivated successfully.
Jul 07 15:46:46 minikube systemd[1]: Stopped Docker Application Container Engine.
Jul 07 15:46:46 minikube systemd[1]: Starting Docker Application Container Engine...
Jul 07 15:46:46 minikube dockerd[1232]: time="2024-07-07T15:46:46.723219183Z" level=info msg="Starting up"
Jul 07 15:46:46 minikube dockerd[1232]: time="2024-07-07T15:46:46.774250987Z" level=info msg="[graphdriver] trying configured driver: overlay2"
Jul 07 15:46:46 minikube dockerd[1232]: time="2024-07-07T15:46:46.813022870Z" level=info msg="Loading containers: start."
Jul 07 15:46:47 minikube dockerd[1232]: time="2024-07-07T15:46:47.064908463Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Jul 07 15:46:47 minikube dockerd[1232]: time="2024-07-07T15:46:47.146105014Z" level=info msg="Loading containers: done."
Jul 07 15:46:47 minikube dockerd[1232]: time="2024-07-07T15:46:47.172936956Z" level=warning msg="WARNING: No blkio throttle.read_bps_device support"
Jul 07 15:46:47 minikube dockerd[1232]: time="2024-07-07T15:46:47.173051048Z" level=warning msg="WARNING: No blkio throttle.write_bps_device support"
Jul 07 15:46:47 minikube dockerd[1232]: time="2024-07-07T15:46:47.173077550Z" level=warning msg="WARNING: No blkio throttle.read_iops_device support"
Jul 07 15:46:47 minikube dockerd[1232]: time="2024-07-07T15:46:47.173089574Z" level=warning msg="WARNING: No blkio throttle.write_iops_device support"
Jul 07 15:46:47 minikube dockerd[1232]: time="2024-07-07T15:46:47.173148529Z" level=info msg="Docker daemon" commit=ac2de55 containerd-snapshotter=false storage-driver=overlay2 version=26.1.1
Jul 07 15:46:47 minikube dockerd[1232]: time="2024-07-07T15:46:47.173228354Z" level=info msg="Daemon has completed initialization"
Jul 07 15:46:47 minikube dockerd[1232]: time="2024-07-07T15:46:47.252284593Z" level=info msg="API listen on /var/run/docker.sock"
Jul 07 15:46:47 minikube dockerd[1232]: time="2024-07-07T15:46:47.252342843Z" level=info msg="API listen on [::]:2376"
Jul 07 15:46:47 minikube systemd[1]: Started Docker Application Container Engine.
Jul 07 15:46:48 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Jul 07 15:46:48 minikube cri-dockerd[1456]: time="2024-07-07T15:46:48Z" level=info msg="Starting cri-dockerd dev (HEAD)"
Jul 07 15:46:48 minikube cri-dockerd[1456]: time="2024-07-07T15:46:48Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Jul 07 15:46:48 minikube cri-dockerd[1456]: time="2024-07-07T15:46:48Z" level=info msg="Start docker client with request timeout 0s"
Jul 07 15:46:48 minikube cri-dockerd[1456]: time="2024-07-07T15:46:48Z" level=info msg="Hairpin mode is set to hairpin-veth"
Jul 07 15:46:48 minikube cri-dockerd[1456]: time="2024-07-07T15:46:48Z" level=info msg="Loaded network plugin cni"
Jul 07 15:46:48 minikube cri-dockerd[1456]: time="2024-07-07T15:46:48Z" level=info msg="Docker cri networking managed by network plugin cni"
Jul 07 15:46:48 minikube cri-dockerd[1456]: time="2024-07-07T15:46:48Z" level=info msg="Setting cgroupDriver cgroupfs"
Jul 07 15:46:48 minikube cri-dockerd[1456]: time="2024-07-07T15:46:48Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Jul 07 15:46:48 minikube cri-dockerd[1456]: time="2024-07-07T15:46:48Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Jul 07 15:46:48 minikube cri-dockerd[1456]: time="2024-07-07T15:46:48Z" level=info msg="Start cri-dockerd grpc backend"
Jul 07 15:46:48 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.
Jul 07 15:47:00 minikube cri-dockerd[1456]: time="2024-07-07T15:47:00Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/893996fa039cf66fce674af539b9955f342a740034e4deeaac2c0796affcb425/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Jul 07 15:47:00 minikube cri-dockerd[1456]: time="2024-07-07T15:47:00Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/a4e04e1c2db624bdbb9987af05156cb78136fbebc5ca88572e80ee42bbe5e61d/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Jul 07 15:47:00 minikube cri-dockerd[1456]: time="2024-07-07T15:47:00Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/51fc996278f888af4bcad9b31b146c573fc5e71780d4b37eb0212087bf48b912/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Jul 07 15:47:00 minikube cri-dockerd[1456]: time="2024-07-07T15:47:00Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/15ffec42962e562ea671fbacc48da3581f396e068684a97ca84ff4824cb4c7d8/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Jul 07 15:47:26 minikube cri-dockerd[1456]: time="2024-07-07T15:47:26Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/78a93625c52cb225eb111d8bfce61349d589324b8d9edd6383fe6a4380b767c7/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Jul 07 15:47:26 minikube cri-dockerd[1456]: time="2024-07-07T15:47:26Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/6d4d57cf0ecbd4dc59a81feab94a69cf4e6202e19e2b3210d22651e034c75831/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Jul 07 15:47:27 minikube cri-dockerd[1456]: time="2024-07-07T15:47:27Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/d2b6c080126a7f54363ef832b580c71b7d94cff9a707dc880ba2b5638c305c49/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Jul 07 15:47:33 minikube cri-dockerd[1456]: time="2024-07-07T15:47:33Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:10.244.0.0/24,},}"
Jul 07 15:48:02 minikube cri-dockerd[1456]: time="2024-07-07T15:48:02Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/40d5b3fcb0f35f957e4319c42d2a56f753b34c4e74b99f06942dd14edadb3c86/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Jul 07 15:48:18 minikube cri-dockerd[1456]: time="2024-07-07T15:48:18Z" level=info msg="Pulling image sandeep114/sketchboard:latest: 3dbed71fc544: Downloading [=======>                                           ]  9.132MB/64.14MB"
Jul 07 15:48:28 minikube cri-dockerd[1456]: time="2024-07-07T15:48:28Z" level=info msg="Pulling image sandeep114/sketchboard:latest: 58b365fa3e8d: Downloading [=================================================> ]  23.87MB/24.05MB"
Jul 07 15:48:38 minikube cri-dockerd[1456]: time="2024-07-07T15:48:38Z" level=info msg="Pulling image sandeep114/sketchboard:latest: 3dbed71fc544: Downloading [=====================>                             ]  27.88MB/64.14MB"
Jul 07 15:48:48 minikube cri-dockerd[1456]: time="2024-07-07T15:48:48Z" level=info msg="Pulling image sandeep114/sketchboard:latest: ae70830af8b6: Downloading [=======>                                           ]  33.32MB/211.2MB"
Jul 07 15:48:58 minikube cri-dockerd[1456]: time="2024-07-07T15:48:58Z" level=info msg="Pulling image sandeep114/sketchboard:latest: ae70830af8b6: Downloading [===========>                                       ]  48.38MB/211.2MB"
Jul 07 15:49:08 minikube cri-dockerd[1456]: time="2024-07-07T15:49:08Z" level=info msg="Pulling image sandeep114/sketchboard:latest: 11ee31c98c92: Downloading [=====================>                             ]  22.67MB/53.03MB"
Jul 07 15:49:18 minikube cri-dockerd[1456]: time="2024-07-07T15:49:18Z" level=info msg="Pulling image sandeep114/sketchboard:latest: 3dbed71fc544: Extracting [=============>                                     ]  17.83MB/64.14MB"
Jul 07 15:49:28 minikube cri-dockerd[1456]: time="2024-07-07T15:49:28Z" level=info msg="Pulling image sandeep114/sketchboard:latest: ae70830af8b6: Downloading [=====================>                             ]  88.73MB/211.2MB"
Jul 07 15:49:38 minikube cri-dockerd[1456]: time="2024-07-07T15:49:38Z" level=info msg="Pulling image sandeep114/sketchboard:latest: ae70830af8b6: Downloading [=============================>                     ]  125.3MB/211.2MB"
Jul 07 15:49:48 minikube cri-dockerd[1456]: time="2024-07-07T15:49:48Z" level=info msg="Pulling image sandeep114/sketchboard:latest: ae70830af8b6: Downloading [======================================>            ]  163.5MB/211.2MB"
Jul 07 15:49:58 minikube cri-dockerd[1456]: time="2024-07-07T15:49:58Z" level=info msg="Pulling image sandeep114/sketchboard:latest: ae70830af8b6: Downloading [===============================================>   ]  200.6MB/211.2MB"


==> container status <==
CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
5a414fa525282       cbb01a7bd410d       2 minutes ago       Running             coredns                   0                   d2b6c080126a7       coredns-7db6d8ff4d-fcxg5
f1fdd34bf9b24       a0bf559e280cf       2 minutes ago       Running             kube-proxy                0                   6d4d57cf0ecbd       kube-proxy-fpg57
b98938001a3e8       6e38f40d628db       2 minutes ago       Running             storage-provisioner       0                   78a93625c52cb       storage-provisioner
e1dc82810fefb       259c8277fcbbc       3 minutes ago       Running             kube-scheduler            0                   15ffec42962e5       kube-scheduler-minikube
d41c9654eb45e       c42f13656d0b2       3 minutes ago       Running             kube-apiserver            0                   51fc996278f88       kube-apiserver-minikube
7c3db8062b35c       3861cfcd7c04c       3 minutes ago       Running             etcd                      0                   a4e04e1c2db62       etcd-minikube
e132fc33e2021       c7aad43836fa5       3 minutes ago       Running             kube-controller-manager   0                   893996fa039cf       kube-controller-manager-minikube


==> coredns [5a414fa52528] <==
.:53
[INFO] plugin/reload: Running configuration SHA512 = f869070685748660180df1b7a47d58cdafcf2f368266578c062d1151dc2c900964aecc5975e8882e6de6fdfb6460463e30ebfaad2ec8f0c3c6436f80225b3b5b
CoreDNS-1.11.1
linux/amd64, go1.20.7, ae2bbc2
[INFO] 127.0.0.1:32994 - 10985 "HINFO IN 4751419436969842074.3774017243561056653. udp 57 false 512" NXDOMAIN qr,rd,ra 57 0.051466934s


==> describe nodes <==
Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=5883c09216182566a63dff4c326a6fc9ed2982ff
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2024_07_07T21_17_12_0700
                    minikube.k8s.io/version=v1.33.1
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Sun, 07 Jul 2024 15:47:07 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Sun, 07 Jul 2024 15:49:55 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Sun, 07 Jul 2024 15:47:33 +0000   Sun, 07 Jul 2024 15:47:04 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Sun, 07 Jul 2024 15:47:33 +0000   Sun, 07 Jul 2024 15:47:04 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Sun, 07 Jul 2024 15:47:33 +0000   Sun, 07 Jul 2024 15:47:04 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Sun, 07 Jul 2024 15:47:33 +0000   Sun, 07 Jul 2024 15:47:23 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                12
  ephemeral-storage:  1055762868Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             3729400Ki
  pods:               110
Allocatable:
  cpu:                12
  ephemeral-storage:  1055762868Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             3729400Ki
  pods:               110
System Info:
  Machine ID:                 c4d4cdfabae2405b87139771161bc776
  System UUID:                c4d4cdfabae2405b87139771161bc776
  Boot ID:                    bf92f18e-6377-4d66-9d29-469c381358e4
  Kernel Version:             5.15.146.1-microsoft-standard-WSL2
  OS Image:                   Ubuntu 22.04.4 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://26.1.1
  Kubelet Version:            v1.30.0
  Kube-Proxy Version:         v1.30.0
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (8 in total)
  Namespace                   Name                                      CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                      ------------  ----------  ---------------  -------------  ---
  default                     sketchborad-deployment-88cf4c55b-57kjb    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         2m2s
  kube-system                 coredns-7db6d8ff4d-fcxg5                  100m (0%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     2m37s
  kube-system                 etcd-minikube                             100m (0%!)(MISSING)     0 (0%!)(MISSING)      100Mi (2%!)(MISSING)       0 (0%!)(MISSING)         2m52s
  kube-system                 kube-apiserver-minikube                   250m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         2m50s
  kube-system                 kube-controller-manager-minikube          200m (1%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         2m54s
  kube-system                 kube-proxy-fpg57                          0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         2m38s
  kube-system                 kube-scheduler-minikube                   100m (0%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         2m52s
  kube-system                 storage-provisioner                       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         2m47s
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                750m (6%!)(MISSING)   0 (0%!)(MISSING)
  memory             170Mi (4%!)(MISSING)  170Mi (4%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                  From             Message
  ----    ------                   ----                 ----             -------
  Normal  Starting                 2m35s                kube-proxy       
  Normal  Starting                 3m5s                 kubelet          Starting kubelet.
  Normal  NodeHasSufficientMemory  3m5s (x8 over 3m5s)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    3m5s (x8 over 3m5s)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     3m5s (x7 over 3m5s)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeAllocatableEnforced  3m5s                 kubelet          Updated Node Allocatable limit across pods
  Normal  Starting                 2m51s                kubelet          Starting kubelet.
  Normal  NodeHasSufficientMemory  2m51s                kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    2m51s                kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     2m51s                kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeNotReady             2m51s                kubelet          Node minikube status is now: NodeNotReady
  Normal  NodeAllocatableEnforced  2m50s                kubelet          Updated Node Allocatable limit across pods
  Normal  NodeReady                2m40s                kubelet          Node minikube status is now: NodeReady
  Normal  RegisteredNode           2m38s                node-controller  Node minikube event: Registered Node minikube in Controller


==> dmesg <==
[  +0.000713] FS-Cache: N-cookie c=00000005 [p=00000002 fl=2 nc=0 na=1]
[  +0.000735] FS-Cache: N-cookie d=000000001575debc{9P.session} n=000000000eccdac8
[  +0.000834] FS-Cache: N-key=[10] '34323934393337353131'
[  +0.005792] FS-Cache: Duplicate cookie detected
[  +0.000744] FS-Cache: O-cookie c=00000006 [p=00000002 fl=222 nc=0 na=1]
[  +0.000747] FS-Cache: O-cookie d=000000001575debc{9P.session} n=0000000084013612
[  +0.001060] FS-Cache: O-key=[10] '34323934393337353132'
[  +0.000670] FS-Cache: N-cookie c=00000007 [p=00000002 fl=2 nc=0 na=1]
[  +0.000907] FS-Cache: N-cookie d=000000001575debc{9P.session} n=00000000bc336acc
[  +0.001032] FS-Cache: N-key=[10] '34323934393337353132'
[  +4.082299] FS-Cache: Duplicate cookie detected
[  +0.000728] FS-Cache: O-cookie c=0000000b [p=00000002 fl=222 nc=0 na=1]
[  +0.000636] FS-Cache: O-cookie d=000000001575debc{9P.session} n=00000000c9f381aa
[  +0.000707] FS-Cache: O-key=[10] '34323934393337393231'
[  +0.000447] FS-Cache: N-cookie c=0000000c [p=00000002 fl=2 nc=0 na=1]
[  +0.000558] FS-Cache: N-cookie d=000000001575debc{9P.session} n=000000001bc95656
[  +0.000667] FS-Cache: N-key=[10] '34323934393337393231'
[  +0.012078] WSL (2) ERROR: UtilCreateProcessAndWait:665: /bin/mount failed with 2
[  +0.001747] WSL (1) ERROR: UtilCreateProcessAndWait:687: /bin/mount failed with status 0xff00

[  +0.001416] WSL (1) ERROR: ConfigMountFsTab:2589: Processing fstab with mount -a failed.
[  +0.002793] WSL (1) ERROR: ConfigApplyWindowsLibPath:2537: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000006]  failed 2
[  +0.004279] WSL (3) ERROR: UtilCreateProcessAndWait:665: /bin/mount failed with 2
[  +0.001115] WSL (1) ERROR: UtilCreateProcessAndWait:687: /bin/mount failed with status 0xff00

[  +0.002284] WSL (4) ERROR: UtilCreateProcessAndWait:665: /bin/mount failed with 2
[  +0.001000] WSL (1) ERROR: UtilCreateProcessAndWait:687: /bin/mount failed with status 0xff00

[  +0.014359] WSL (1) WARNING: /usr/share/zoneinfo/Asia/Calcutta not found. Is the tzdata package installed?
[  +0.390109] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000954] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000927] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.001051] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -2
[  +2.697611] WSL (2) ERROR: UtilCreateProcessAndWait:665: /bin/mount failed with 2
[  +0.001144] WSL (1) ERROR: UtilCreateProcessAndWait:687: /bin/mount failed with status 0xff00

[  +0.001390] WSL (1) ERROR: ConfigMountFsTab:2589: Processing fstab with mount -a failed.
[  +0.003205] WSL (1) ERROR: ConfigApplyWindowsLibPath:2537: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000005]  failed 2
[  +0.005259] WSL (3) ERROR: UtilCreateProcessAndWait:665: /bin/mount failed with 2
[  +0.001107] WSL (1) ERROR: UtilCreateProcessAndWait:687: /bin/mount failed with status 0xff00

[  +0.002353] WSL (4) ERROR: UtilCreateProcessAndWait:665: /bin/mount failed with 2
[  +0.001009] WSL (1) ERROR: UtilCreateProcessAndWait:687: /bin/mount failed with status 0xff00

[  +0.013908] WSL (1) WARNING: /usr/share/zoneinfo/Asia/Calcutta not found. Is the tzdata package installed?
[  +0.171456] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.001005] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000958] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.001085] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -2
[  +0.042660] WSL (1) ERROR: ConfigApplyWindowsLibPath:2537: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000006]  failed 2
[  +0.033284] WSL (1) WARNING: /usr/share/zoneinfo/Asia/Calcutta not found. Is the tzdata package installed?
[  +0.168485] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.001684] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.001449] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.001677] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -2
[ +15.979655] netlink: 'init': attribute type 4 has an invalid length.
[  +0.243661] kmem.limit_in_bytes is deprecated and will be removed. Please report your usecase to linux-mm@kvack.org if you depend on this functionality.


==> etcd [7c3db8062b35] <==
{"level":"info","ts":"2024-07-07T15:47:01.760231Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2024-07-07T15:47:01.760243Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 1"}
{"level":"info","ts":"2024-07-07T15:47:01.760295Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"warn","ts":"2024-07-07T15:47:01.84388Z","caller":"auth/store.go:1241","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2024-07-07T15:47:01.852881Z","caller":"mvcc/kvstore.go:407","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2024-07-07T15:47:01.860916Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2024-07-07T15:47:01.937442Z","caller":"etcdserver/server.go:860","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.12","cluster-version":"to_be_decided"}
{"level":"info","ts":"2024-07-07T15:47:01.938401Z","caller":"etcdserver/server.go:744","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"aec36adc501070cc","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2024-07-07T15:47:01.93872Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2024-07-07T15:47:01.940247Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2024-07-07T15:47:01.940299Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2024-07-07T15:47:01.942986Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2024-07-07T15:47:01.94327Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","added-peer-id":"aec36adc501070cc","added-peer-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2024-07-07T15:47:01.946945Z","caller":"embed/etcd.go:726","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2024-07-07T15:47:01.947303Z","caller":"embed/etcd.go:597","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-07-07T15:47:01.947475Z","caller":"embed/etcd.go:569","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-07-07T15:47:01.947681Z","caller":"embed/etcd.go:277","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2024-07-07T15:47:01.947861Z","caller":"embed/etcd.go:857","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2024-07-07T15:47:02.361427Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 1"}
{"level":"info","ts":"2024-07-07T15:47:02.36153Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 1"}
{"level":"info","ts":"2024-07-07T15:47:02.361588Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 1"}
{"level":"info","ts":"2024-07-07T15:47:02.361624Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 2"}
{"level":"info","ts":"2024-07-07T15:47:02.361631Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 2"}
{"level":"info","ts":"2024-07-07T15:47:02.361643Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 2"}
{"level":"info","ts":"2024-07-07T15:47:02.361653Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 2"}
{"level":"info","ts":"2024-07-07T15:47:02.36552Z","caller":"etcdserver/server.go:2578","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2024-07-07T15:47:02.369343Z","caller":"etcdserver/server.go:2068","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2024-07-07T15:47:02.369401Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2024-07-07T15:47:02.369502Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2024-07-07T15:47:02.370344Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2024-07-07T15:47:02.370528Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2024-07-07T15:47:02.373111Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","cluster-version":"3.5"}
{"level":"info","ts":"2024-07-07T15:47:02.373736Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2024-07-07T15:47:02.373906Z","caller":"etcdserver/server.go:2602","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2024-07-07T15:47:02.37527Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"192.168.49.2:2379"}
{"level":"info","ts":"2024-07-07T15:47:02.376625Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"127.0.0.1:2379"}
{"level":"warn","ts":"2024-07-07T15:47:07.833278Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"101.238807ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/namespaces/kube-system\" ","response":"range_response_count:0 size:4"}
{"level":"warn","ts":"2024-07-07T15:47:07.833963Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"101.406799ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/masterleases/192.168.49.2\" ","response":"range_response_count:0 size:4"}
{"level":"info","ts":"2024-07-07T15:47:07.834083Z","caller":"traceutil/trace.go:171","msg":"trace[1478461377] range","detail":"{range_begin:/registry/masterleases/192.168.49.2; range_end:; response_count:0; response_revision:10; }","duration":"102.284405ms","start":"2024-07-07T15:47:07.731776Z","end":"2024-07-07T15:47:07.83406Z","steps":["trace[1478461377] 'agreement among raft nodes before linearized reading'  (duration: 101.371026ms)"],"step_count":1}
{"level":"info","ts":"2024-07-07T15:47:07.833968Z","caller":"traceutil/trace.go:171","msg":"trace[118491528] range","detail":"{range_begin:/registry/namespaces/kube-system; range_end:; response_count:0; response_revision:10; }","duration":"101.981609ms","start":"2024-07-07T15:47:07.731947Z","end":"2024-07-07T15:47:07.833929Z","steps":["trace[118491528] 'agreement among raft nodes before linearized reading'  (duration: 101.171099ms)"],"step_count":1}
{"level":"warn","ts":"2024-07-07T15:47:07.833374Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"100.978766ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/namespaces/kube-system\" ","response":"range_response_count:0 size:4"}
{"level":"info","ts":"2024-07-07T15:47:07.834417Z","caller":"traceutil/trace.go:171","msg":"trace[650696827] range","detail":"{range_begin:/registry/namespaces/kube-system; range_end:; response_count:0; response_revision:10; }","duration":"102.053201ms","start":"2024-07-07T15:47:07.73233Z","end":"2024-07-07T15:47:07.834383Z","steps":["trace[650696827] 'agreement among raft nodes before linearized reading'  (duration: 100.757165ms)"],"step_count":1}
{"level":"warn","ts":"2024-07-07T15:47:07.837377Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"186.658598ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/minions/minikube\" ","response":"range_response_count:0 size:4"}
{"level":"info","ts":"2024-07-07T15:47:07.837554Z","caller":"traceutil/trace.go:171","msg":"trace[994098107] range","detail":"{range_begin:/registry/minions/minikube; range_end:; response_count:0; response_revision:10; }","duration":"187.073445ms","start":"2024-07-07T15:47:07.650445Z","end":"2024-07-07T15:47:07.837518Z","steps":["trace[994098107] 'agreement among raft nodes before linearized reading'  (duration: 182.639014ms)"],"step_count":1}
{"level":"info","ts":"2024-07-07T15:47:08.034647Z","caller":"traceutil/trace.go:171","msg":"trace[1844273301] linearizableReadLoop","detail":"{readStateIndex:23; appliedIndex:22; }","duration":"101.283851ms","start":"2024-07-07T15:47:07.933333Z","end":"2024-07-07T15:47:08.034617Z","steps":["trace[1844273301] 'read index received'  (duration: 96.937674ms)","trace[1844273301] 'applied index is now lower than readState.Index'  (duration: 4.340696ms)"],"step_count":2}
{"level":"info","ts":"2024-07-07T15:47:08.035033Z","caller":"traceutil/trace.go:171","msg":"trace[682544975] transaction","detail":"{read_only:false; response_revision:19; number_of_response:1; }","duration":"104.611338ms","start":"2024-07-07T15:47:07.930399Z","end":"2024-07-07T15:47:08.035011Z","steps":["trace[682544975] 'process raft request'  (duration: 98.874238ms)"],"step_count":1}
{"level":"warn","ts":"2024-07-07T15:47:08.063644Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"130.276456ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:4"}
{"level":"info","ts":"2024-07-07T15:47:08.063789Z","caller":"traceutil/trace.go:171","msg":"trace[988087502] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:19; }","duration":"130.434488ms","start":"2024-07-07T15:47:07.933326Z","end":"2024-07-07T15:47:08.06376Z","steps":["trace[988087502] 'agreement among raft nodes before linearized reading'  (duration: 101.794417ms)","trace[988087502] 'range keys from in-memory index tree'  (duration: 28.444593ms)"],"step_count":2}
{"level":"info","ts":"2024-07-07T15:47:08.064511Z","caller":"traceutil/trace.go:171","msg":"trace[277715406] transaction","detail":"{read_only:false; response_revision:20; number_of_response:1; }","duration":"122.853343ms","start":"2024-07-07T15:47:07.941623Z","end":"2024-07-07T15:47:08.064476Z","steps":["trace[277715406] 'process raft request'  (duration: 101.480998ms)","trace[277715406] 'compare'  (duration: 19.885694ms)"],"step_count":2}
{"level":"warn","ts":"2024-07-07T15:47:08.06486Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"120.142841ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/resourcequotas/kube-public/\" range_end:\"/registry/resourcequotas/kube-public0\" ","response":"range_response_count:0 size:4"}
{"level":"info","ts":"2024-07-07T15:47:08.064943Z","caller":"traceutil/trace.go:171","msg":"trace[81715547] range","detail":"{range_begin:/registry/resourcequotas/kube-public/; range_end:/registry/resourcequotas/kube-public0; response_count:0; response_revision:27; }","duration":"120.278958ms","start":"2024-07-07T15:47:07.944643Z","end":"2024-07-07T15:47:08.064922Z","steps":["trace[81715547] 'agreement among raft nodes before linearized reading'  (duration: 120.069331ms)"],"step_count":1}
{"level":"warn","ts":"2024-07-07T15:47:08.065235Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"123.301365ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/namespaces/kube-system\" ","response":"range_response_count:1 size:350"}
{"level":"info","ts":"2024-07-07T15:47:08.065285Z","caller":"traceutil/trace.go:171","msg":"trace[1625818216] range","detail":"{range_begin:/registry/namespaces/kube-system; range_end:; response_count:1; response_revision:27; }","duration":"123.359223ms","start":"2024-07-07T15:47:07.94191Z","end":"2024-07-07T15:47:08.065269Z","steps":["trace[1625818216] 'agreement among raft nodes before linearized reading'  (duration: 123.262166ms)"],"step_count":1}
{"level":"warn","ts":"2024-07-07T15:47:08.072429Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"130.177558ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/csinodes/minikube\" ","response":"range_response_count:0 size:4"}
{"level":"info","ts":"2024-07-07T15:47:08.07259Z","caller":"traceutil/trace.go:171","msg":"trace[223998044] range","detail":"{range_begin:/registry/csinodes/minikube; range_end:; response_count:0; response_revision:27; }","duration":"130.387587ms","start":"2024-07-07T15:47:07.942173Z","end":"2024-07-07T15:47:08.072561Z","steps":["trace[223998044] 'agreement among raft nodes before linearized reading'  (duration: 122.527635ms)"],"step_count":1}
{"level":"info","ts":"2024-07-07T15:47:10.127781Z","caller":"traceutil/trace.go:171","msg":"trace[1980207702] linearizableReadLoop","detail":"{readStateIndex:188; appliedIndex:187; }","duration":"114.451064ms","start":"2024-07-07T15:47:10.013304Z","end":"2024-07-07T15:47:10.127755Z","steps":["trace[1980207702] 'read index received'  (duration: 26.779275ms)","trace[1980207702] 'applied index is now lower than readState.Index'  (duration: 87.670156ms)"],"step_count":2}
{"level":"info","ts":"2024-07-07T15:47:10.127841Z","caller":"traceutil/trace.go:171","msg":"trace[21255004] transaction","detail":"{read_only:false; response_revision:182; number_of_response:1; }","duration":"116.202387ms","start":"2024-07-07T15:47:10.01161Z","end":"2024-07-07T15:47:10.127813Z","steps":["trace[21255004] 'process raft request'  (duration: 28.448108ms)","trace[21255004] 'compare'  (duration: 87.511437ms)"],"step_count":2}
{"level":"warn","ts":"2024-07-07T15:47:10.127977Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"114.692837ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/clusterrolebindings/system:service-account-issuer-discovery\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-07-07T15:47:10.128026Z","caller":"traceutil/trace.go:171","msg":"trace[916197080] range","detail":"{range_begin:/registry/clusterrolebindings/system:service-account-issuer-discovery; range_end:; response_count:0; response_revision:182; }","duration":"114.790245ms","start":"2024-07-07T15:47:10.013217Z","end":"2024-07-07T15:47:10.128008Z","steps":["trace[916197080] 'agreement among raft nodes before linearized reading'  (duration: 114.670081ms)"],"step_count":1}
2024/07/07 15:47:12 WARNING: [core] [Server #8] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"


==> kernel <==
 15:50:03 up 13 min,  0 users,  load average: 2.99, 1.81, 0.89
Linux minikube 5.15.146.1-microsoft-standard-WSL2 #1 SMP Thu Jan 11 04:09:03 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.4 LTS"


==> kube-apiserver [d41c9654eb45] <==
I0707 15:47:07.586542       1 shared_informer.go:313] Waiting for caches to sync for crd-autoregister
I0707 15:47:07.586541       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0707 15:47:07.586516       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0707 15:47:07.586690       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0707 15:47:07.587155       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0707 15:47:07.586982       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0707 15:47:07.587685       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0707 15:47:07.587985       1 controller.go:116] Starting legacy_token_tracking_controller
I0707 15:47:07.588015       1 shared_informer.go:313] Waiting for caches to sync for configmaps
I0707 15:47:07.588116       1 customresource_discovery_controller.go:289] Starting DiscoveryController
I0707 15:47:07.588187       1 controller.go:139] Starting OpenAPI controller
I0707 15:47:07.588243       1 controller.go:87] Starting OpenAPI V3 controller
I0707 15:47:07.588278       1 naming_controller.go:291] Starting NamingConditionController
I0707 15:47:07.588297       1 establishing_controller.go:76] Starting EstablishingController
I0707 15:47:07.588335       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0707 15:47:07.587027       1 controller.go:78] Starting OpenAPI AggregationController
I0707 15:47:07.587047       1 controller.go:80] Starting OpenAPI V3 AggregationController
I0707 15:47:07.587581       1 available_controller.go:423] Starting AvailableConditionController
I0707 15:47:07.588558       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0707 15:47:07.588711       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0707 15:47:07.588785       1 crd_finalizer.go:266] Starting CRDFinalizer
I0707 15:47:07.729241       1 shared_informer.go:320] Caches are synced for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0707 15:47:07.729794       1 shared_informer.go:320] Caches are synced for cluster_authentication_trust_controller
I0707 15:47:07.729873       1 shared_informer.go:320] Caches are synced for configmaps
I0707 15:47:07.729810       1 policy_source.go:224] refreshing policies
I0707 15:47:07.729922       1 apf_controller.go:379] Running API Priority and Fairness config worker
I0707 15:47:07.729951       1 apf_controller.go:382] Running API Priority and Fairness periodic rebalancing process
I0707 15:47:07.730002       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0707 15:47:07.730260       1 shared_informer.go:320] Caches are synced for node_authorizer
I0707 15:47:07.730367       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0707 15:47:07.730442       1 handler_discovery.go:447] Starting ResourceDiscoveryManager
I0707 15:47:07.729894       1 shared_informer.go:320] Caches are synced for crd-autoregister
I0707 15:47:07.730606       1 aggregator.go:165] initial CRD sync complete...
I0707 15:47:07.730616       1 autoregister_controller.go:141] Starting autoregister controller
I0707 15:47:07.730623       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0707 15:47:07.730631       1 cache.go:39] Caches are synced for autoregister controller
I0707 15:47:07.735539       1 controller.go:615] quota admission added evaluator for: namespaces
E0707 15:47:07.837338       1 controller.go:145] "Failed to ensure lease exists, will retry" err="namespaces \"kube-system\" not found" interval="200ms"
I0707 15:47:08.070734       1 controller.go:615] quota admission added evaluator for: leases.coordination.k8s.io
I0707 15:47:08.669523       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I0707 15:47:08.749726       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I0707 15:47:08.749831       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0707 15:47:10.708214       1 controller.go:615] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0707 15:47:10.835365       1 controller.go:615] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0707 15:47:10.990842       1 alloc.go:330] "allocated clusterIPs" service="default/kubernetes" clusterIPs={"IPv4":"10.96.0.1"}
W0707 15:47:11.010146       1 lease.go:265] Resetting endpoints for master service "kubernetes" to [192.168.49.2]
I0707 15:47:11.012499       1 controller.go:615] quota admission added evaluator for: endpoints
I0707 15:47:11.024750       1 controller.go:615] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0707 15:47:11.661511       1 controller.go:615] quota admission added evaluator for: serviceaccounts
E0707 15:47:12.260596       1 writers.go:122] apiserver was unable to write a JSON response: http: Handler timeout
E0707 15:47:12.260683       1 status.go:71] apiserver received an error that is not an metav1.Status: &errors.errorString{s:"http: Handler timeout"}: http: Handler timeout
E0707 15:47:12.260717       1 finisher.go:175] FinishRequest: post-timeout activity - time-elapsed: 30.202Âµs, panicked: false, err: context canceled, panic-reason: <nil>
E0707 15:47:12.262005       1 writers.go:135] apiserver was unable to write a fallback JSON response: http: Handler timeout
E0707 15:47:12.262258       1 timeout.go:142] post-timeout activity - time-elapsed: 1.664521ms, PATCH "/api/v1/namespaces/kube-system/pods/etcd-minikube/status" result: <nil>
I0707 15:47:12.464311       1 controller.go:615] quota admission added evaluator for: deployments.apps
I0707 15:47:12.491343       1 alloc.go:330] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs={"IPv4":"10.96.0.10"}
I0707 15:47:12.531009       1 controller.go:615] quota admission added evaluator for: daemonsets.apps
I0707 15:47:25.818920       1 controller.go:615] quota admission added evaluator for: replicasets.apps
I0707 15:47:25.870698       1 controller.go:615] quota admission added evaluator for: controllerrevisions.apps
I0707 15:48:01.243299       1 alloc.go:330] "allocated clusterIPs" service="default/sketchboard-service" clusterIPs={"IPv4":"10.110.182.23"}


==> kube-controller-manager [e132fc33e202] <==
I0707 15:47:24.923911       1 shared_informer.go:320] Caches are synced for certificate-csrapproving
I0707 15:47:24.924626       1 shared_informer.go:320] Caches are synced for cronjob
I0707 15:47:24.924715       1 shared_informer.go:320] Caches are synced for PV protection
I0707 15:47:24.924820       1 shared_informer.go:320] Caches are synced for expand
I0707 15:47:24.924850       1 shared_informer.go:320] Caches are synced for crt configmap
I0707 15:47:24.925097       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-client
I0707 15:47:24.925875       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-serving
I0707 15:47:24.926253       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0707 15:47:24.927406       1 shared_informer.go:320] Caches are synced for bootstrap_signer
I0707 15:47:24.930866       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
I0707 15:47:24.937875       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-legacy-unknown
I0707 15:47:24.938446       1 shared_informer.go:320] Caches are synced for TTL after finished
I0707 15:47:24.942914       1 actual_state_of_world.go:543] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"minikube\" does not exist"
I0707 15:47:25.023937       1 shared_informer.go:320] Caches are synced for ephemeral
I0707 15:47:25.024010       1 shared_informer.go:320] Caches are synced for endpoint_slice
I0707 15:47:25.023993       1 shared_informer.go:320] Caches are synced for persistent volume
I0707 15:47:25.024451       1 shared_informer.go:320] Caches are synced for node
I0707 15:47:25.024451       1 shared_informer.go:320] Caches are synced for endpoint
I0707 15:47:25.024587       1 range_allocator.go:175] "Sending events to api server" logger="node-ipam-controller"
I0707 15:47:25.024729       1 range_allocator.go:179] "Starting range CIDR allocator" logger="node-ipam-controller"
I0707 15:47:25.024780       1 shared_informer.go:313] Waiting for caches to sync for cidrallocator
I0707 15:47:25.024795       1 shared_informer.go:320] Caches are synced for cidrallocator
I0707 15:47:25.024476       1 shared_informer.go:320] Caches are synced for taint
I0707 15:47:25.025328       1 node_lifecycle_controller.go:1227] "Initializing eviction metric for zone" logger="node-lifecycle-controller" zone=""
I0707 15:47:25.025653       1 shared_informer.go:320] Caches are synced for job
I0707 15:47:25.025836       1 shared_informer.go:320] Caches are synced for endpoint_slice_mirroring
I0707 15:47:25.026102       1 shared_informer.go:320] Caches are synced for taint-eviction-controller
I0707 15:47:25.026179       1 shared_informer.go:320] Caches are synced for ReplicationController
I0707 15:47:25.026336       1 shared_informer.go:320] Caches are synced for ReplicaSet
I0707 15:47:25.024489       1 shared_informer.go:320] Caches are synced for GC
I0707 15:47:25.024510       1 shared_informer.go:320] Caches are synced for legacy-service-account-token-cleaner
I0707 15:47:25.025573       1 node_lifecycle_controller.go:879] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="minikube"
I0707 15:47:25.027884       1 shared_informer.go:320] Caches are synced for TTL
I0707 15:47:25.027915       1 shared_informer.go:320] Caches are synced for deployment
I0707 15:47:25.028047       1 node_lifecycle_controller.go:1073] "Controller detected that zone is now in new state" logger="node-lifecycle-controller" zone="" newState="Normal"
I0707 15:47:25.027951       1 shared_informer.go:320] Caches are synced for stateful set
I0707 15:47:25.028253       1 shared_informer.go:320] Caches are synced for HPA
I0707 15:47:25.028738       1 shared_informer.go:320] Caches are synced for daemon sets
I0707 15:47:25.030220       1 shared_informer.go:320] Caches are synced for attach detach
I0707 15:47:25.031180       1 shared_informer.go:320] Caches are synced for PVC protection
I0707 15:47:25.041896       1 shared_informer.go:320] Caches are synced for validatingadmissionpolicy-status
I0707 15:47:25.052435       1 range_allocator.go:381] "Set node PodCIDR" logger="node-ipam-controller" node="minikube" podCIDRs=["10.244.0.0/24"]
I0707 15:47:25.124250       1 shared_informer.go:320] Caches are synced for ClusterRoleAggregator
I0707 15:47:25.131224       1 shared_informer.go:320] Caches are synced for resource quota
I0707 15:47:25.133915       1 shared_informer.go:320] Caches are synced for resource quota
I0707 15:47:25.133970       1 shared_informer.go:320] Caches are synced for disruption
I0707 15:47:25.532640       1 shared_informer.go:320] Caches are synced for garbage collector
I0707 15:47:25.595774       1 shared_informer.go:320] Caches are synced for garbage collector
I0707 15:47:25.595845       1 garbagecollector.go:157] "All resource monitors have synced. Proceeding to collect garbage" logger="garbage-collector-controller"
I0707 15:47:26.145236       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-7db6d8ff4d" duration="312.89526ms"
I0707 15:47:26.236260       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-7db6d8ff4d" duration="90.888859ms"
I0707 15:47:26.236528       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-7db6d8ff4d" duration="125.101Âµs"
I0707 15:47:26.249029       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-7db6d8ff4d" duration="171.439Âµs"
I0707 15:47:28.890746       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-7db6d8ff4d" duration="114.546Âµs"
I0707 15:47:28.983776       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-7db6d8ff4d" duration="16.844409ms"
I0707 15:47:28.983919       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-7db6d8ff4d" duration="58.967Âµs"
I0707 15:48:01.350809       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/sketchborad-deployment-88cf4c55b" duration="69.033067ms"
I0707 15:48:01.369505       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/sketchborad-deployment-88cf4c55b" duration="18.603621ms"
I0707 15:48:01.369661       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/sketchborad-deployment-88cf4c55b" duration="54.703Âµs"
I0707 15:48:01.377231       1 replica_set.go:676] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/sketchborad-deployment-88cf4c55b" duration="97.993Âµs"


==> kube-proxy [f1fdd34bf9b2] <==
I0707 15:47:27.908581       1 server_linux.go:69] "Using iptables proxy"
I0707 15:47:27.932297       1 server.go:1062] "Successfully retrieved node IP(s)" IPs=["192.168.49.2"]
I0707 15:47:27.990886       1 server.go:659] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0707 15:47:27.990999       1 server_linux.go:165] "Using iptables Proxier"
I0707 15:47:27.995304       1 server_linux.go:511] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
I0707 15:47:27.995371       1 server_linux.go:528] "Defaulting to no-op detect-local"
I0707 15:47:27.995400       1 proxier.go:243] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0707 15:47:27.996174       1 server.go:872] "Version info" version="v1.30.0"
I0707 15:47:27.997347       1 server.go:874] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0707 15:47:27.999790       1 config.go:192] "Starting service config controller"
I0707 15:47:27.999944       1 shared_informer.go:313] Waiting for caches to sync for service config
I0707 15:47:28.000286       1 config.go:319] "Starting node config controller"
I0707 15:47:28.000301       1 shared_informer.go:313] Waiting for caches to sync for node config
I0707 15:47:28.027753       1 config.go:101] "Starting endpoint slice config controller"
I0707 15:47:28.027872       1 shared_informer.go:313] Waiting for caches to sync for endpoint slice config
I0707 15:47:28.101000       1 shared_informer.go:320] Caches are synced for node config
I0707 15:47:28.101113       1 shared_informer.go:320] Caches are synced for service config
I0707 15:47:28.128484       1 shared_informer.go:320] Caches are synced for endpoint slice config


==> kube-scheduler [e1dc82810fef] <==
E0707 15:47:07.843130       1 reflector.go:150] runtime/asm_amd64.s:1695: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0707 15:47:07.844025       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0707 15:47:07.844152       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0707 15:47:07.844338       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0707 15:47:07.844484       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0707 15:47:07.847917       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0707 15:47:07.848567       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0707 15:47:07.929473       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0707 15:47:07.848848       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0707 15:47:07.851680       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0707 15:47:07.929652       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0707 15:47:07.931135       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0707 15:47:07.931945       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0707 15:47:07.932428       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0707 15:47:07.943069       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0707 15:47:07.946216       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0707 15:47:07.946290       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0707 15:47:07.946378       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0707 15:47:07.946394       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0707 15:47:07.952255       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0707 15:47:07.952405       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0707 15:47:08.030598       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0707 15:47:08.030733       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0707 15:47:08.030799       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0707 15:47:08.031858       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0707 15:47:08.032025       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0707 15:47:08.033378       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0707 15:47:08.037585       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0707 15:47:08.037692       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0707 15:47:08.853898       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0707 15:47:08.853999       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0707 15:47:08.859036       1 reflector.go:547] runtime/asm_amd64.s:1695: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0707 15:47:08.859157       1 reflector.go:150] runtime/asm_amd64.s:1695: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0707 15:47:09.027910       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0707 15:47:09.027990       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0707 15:47:09.069483       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0707 15:47:09.069610       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0707 15:47:09.083018       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0707 15:47:09.083118       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0707 15:47:09.105490       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0707 15:47:09.105578       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0707 15:47:09.191266       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0707 15:47:09.191389       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0707 15:47:09.199490       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0707 15:47:09.199589       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0707 15:47:09.233316       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0707 15:47:09.233490       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0707 15:47:09.233314       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0707 15:47:09.233556       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0707 15:47:09.260571       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0707 15:47:09.260696       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0707 15:47:09.263488       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0707 15:47:09.263597       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0707 15:47:09.402057       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0707 15:47:09.402173       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0707 15:47:09.512874       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0707 15:47:09.512966       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0707 15:47:09.626152       1 reflector.go:547] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0707 15:47:09.626222       1 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
I0707 15:47:11.539360       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file


==> kubelet <==
Jul 07 15:47:12 minikube kubelet[2414]: E0707 15:47:12.843679    2414 kubelet.go:2361] "Skipping pod synchronization" err="container runtime status check may not have completed yet"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.034068    2414 cpu_manager.go:214] "Starting CPU manager" policy="none"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.034144    2414 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.034198    2414 state_mem.go:36] "Initialized new in-memory state store"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.034512    2414 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.034535    2414 state_mem.go:96] "Updated CPUSet assignments" assignments={}
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.034578    2414 policy_none.go:49] "None policy: Start"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.042449    2414 memory_manager.go:170] "Starting memorymanager" policy="None"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.042547    2414 state_mem.go:35] "Initializing new in-memory state store"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.042873    2414 state_mem.go:75] "Updated machine memory state"
Jul 07 15:47:13 minikube kubelet[2414]: E0707 15:47:13.044283    2414 kubelet.go:2361] "Skipping pod synchronization" err="container runtime status check may not have completed yet"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.046393    2414 manager.go:479] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.046718    2414 container_log_manager.go:186] "Initializing container log rotate workers" workers=1 monitorPeriod="10s"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.046995    2414 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.445415    2414 topology_manager.go:215] "Topology Admit Handler" podUID="063d6b9688927e601f52fd818d1305c5" podNamespace="kube-system" podName="etcd-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.445692    2414 topology_manager.go:215] "Topology Admit Handler" podUID="3c555f828409b009ebee39fdbedfcac0" podNamespace="kube-system" podName="kube-apiserver-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.445858    2414 topology_manager.go:215] "Topology Admit Handler" podUID="7fd44e8d11c3e0ffe6b1825e2a1f2270" podNamespace="kube-system" podName="kube-controller-manager-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.446302    2414 topology_manager.go:215] "Topology Admit Handler" podUID="f9c8e1d0d74b1727abdb4b4a31d3a7c1" podNamespace="kube-system" podName="kube-scheduler-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: E0707 15:47:13.469625    2414 kubelet.go:1928] "Failed creating a mirror pod for" err="pods \"etcd-minikube\" already exists" pod="kube-system/etcd-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: E0707 15:47:13.471364    2414 kubelet.go:1928] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-minikube\" already exists" pod="kube-system/kube-controller-manager-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: E0707 15:47:13.471504    2414 kubelet.go:1928] "Failed creating a mirror pod for" err="pods \"kube-scheduler-minikube\" already exists" pod="kube-system/kube-scheduler-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.542043    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/7fd44e8d11c3e0ffe6b1825e2a1f2270-flexvolume-dir\") pod \"kube-controller-manager-minikube\" (UID: \"7fd44e8d11c3e0ffe6b1825e2a1f2270\") " pod="kube-system/kube-controller-manager-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.542209    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/7fd44e8d11c3e0ffe6b1825e2a1f2270-k8s-certs\") pod \"kube-controller-manager-minikube\" (UID: \"7fd44e8d11c3e0ffe6b1825e2a1f2270\") " pod="kube-system/kube-controller-manager-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.542338    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/7fd44e8d11c3e0ffe6b1825e2a1f2270-usr-local-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"7fd44e8d11c3e0ffe6b1825e2a1f2270\") " pod="kube-system/kube-controller-manager-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.542396    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/063d6b9688927e601f52fd818d1305c5-etcd-data\") pod \"etcd-minikube\" (UID: \"063d6b9688927e601f52fd818d1305c5\") " pod="kube-system/etcd-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.542489    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/3c555f828409b009ebee39fdbedfcac0-etc-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"3c555f828409b009ebee39fdbedfcac0\") " pod="kube-system/kube-apiserver-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.542621    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/3c555f828409b009ebee39fdbedfcac0-k8s-certs\") pod \"kube-apiserver-minikube\" (UID: \"3c555f828409b009ebee39fdbedfcac0\") " pod="kube-system/kube-apiserver-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.542748    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/3c555f828409b009ebee39fdbedfcac0-usr-local-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"3c555f828409b009ebee39fdbedfcac0\") " pod="kube-system/kube-apiserver-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.542934    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/7fd44e8d11c3e0ffe6b1825e2a1f2270-etc-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"7fd44e8d11c3e0ffe6b1825e2a1f2270\") " pod="kube-system/kube-controller-manager-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.542982    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/f9c8e1d0d74b1727abdb4b4a31d3a7c1-kubeconfig\") pod \"kube-scheduler-minikube\" (UID: \"f9c8e1d0d74b1727abdb4b4a31d3a7c1\") " pod="kube-system/kube-scheduler-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.543061    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/7fd44e8d11c3e0ffe6b1825e2a1f2270-usr-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"7fd44e8d11c3e0ffe6b1825e2a1f2270\") " pod="kube-system/kube-controller-manager-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.543102    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/3c555f828409b009ebee39fdbedfcac0-ca-certs\") pod \"kube-apiserver-minikube\" (UID: \"3c555f828409b009ebee39fdbedfcac0\") " pod="kube-system/kube-apiserver-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.543131    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/7fd44e8d11c3e0ffe6b1825e2a1f2270-ca-certs\") pod \"kube-controller-manager-minikube\" (UID: \"7fd44e8d11c3e0ffe6b1825e2a1f2270\") " pod="kube-system/kube-controller-manager-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.543413    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/063d6b9688927e601f52fd818d1305c5-etcd-certs\") pod \"etcd-minikube\" (UID: \"063d6b9688927e601f52fd818d1305c5\") " pod="kube-system/etcd-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.543531    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/3c555f828409b009ebee39fdbedfcac0-usr-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"3c555f828409b009ebee39fdbedfcac0\") " pod="kube-system/kube-apiserver-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.544679    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/7fd44e8d11c3e0ffe6b1825e2a1f2270-kubeconfig\") pod \"kube-controller-manager-minikube\" (UID: \"7fd44e8d11c3e0ffe6b1825e2a1f2270\") " pod="kube-system/kube-controller-manager-minikube"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.594686    2414 apiserver.go:52] "Watching apiserver"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.637943    2414 desired_state_of_world_populator.go:157] "Finished populating initial desired state of world"
Jul 07 15:47:13 minikube kubelet[2414]: I0707 15:47:13.930372    2414 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/kube-apiserver-minikube" podStartSLOduration=0.930326189 podStartE2EDuration="930.326189ms" podCreationTimestamp="2024-07-07 15:47:13 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2024-07-07 15:47:13.930204634 +0000 UTC m=+1.523616436" watchObservedRunningTime="2024-07-07 15:47:13.930326189 +0000 UTC m=+1.523738000"
Jul 07 15:47:25 minikube kubelet[2414]: I0707 15:47:25.304479    2414 topology_manager.go:215] "Topology Admit Handler" podUID="aa4600a6-7b3a-4b0a-9fcd-6b5f9a791af2" podNamespace="kube-system" podName="storage-provisioner"
Jul 07 15:47:25 minikube kubelet[2414]: I0707 15:47:25.341969    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/host-path/aa4600a6-7b3a-4b0a-9fcd-6b5f9a791af2-tmp\") pod \"storage-provisioner\" (UID: \"aa4600a6-7b3a-4b0a-9fcd-6b5f9a791af2\") " pod="kube-system/storage-provisioner"
Jul 07 15:47:25 minikube kubelet[2414]: I0707 15:47:25.342093    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-ns2nf\" (UniqueName: \"kubernetes.io/projected/aa4600a6-7b3a-4b0a-9fcd-6b5f9a791af2-kube-api-access-ns2nf\") pod \"storage-provisioner\" (UID: \"aa4600a6-7b3a-4b0a-9fcd-6b5f9a791af2\") " pod="kube-system/storage-provisioner"
Jul 07 15:47:25 minikube kubelet[2414]: I0707 15:47:25.941155    2414 topology_manager.go:215] "Topology Admit Handler" podUID="648a91c9-72e3-4522-9b7f-63efbd21c9a3" podNamespace="kube-system" podName="kube-proxy-fpg57"
Jul 07 15:47:26 minikube kubelet[2414]: I0707 15:47:26.048152    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/648a91c9-72e3-4522-9b7f-63efbd21c9a3-xtables-lock\") pod \"kube-proxy-fpg57\" (UID: \"648a91c9-72e3-4522-9b7f-63efbd21c9a3\") " pod="kube-system/kube-proxy-fpg57"
Jul 07 15:47:26 minikube kubelet[2414]: I0707 15:47:26.048316    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/648a91c9-72e3-4522-9b7f-63efbd21c9a3-kube-proxy\") pod \"kube-proxy-fpg57\" (UID: \"648a91c9-72e3-4522-9b7f-63efbd21c9a3\") " pod="kube-system/kube-proxy-fpg57"
Jul 07 15:47:26 minikube kubelet[2414]: I0707 15:47:26.048356    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/648a91c9-72e3-4522-9b7f-63efbd21c9a3-lib-modules\") pod \"kube-proxy-fpg57\" (UID: \"648a91c9-72e3-4522-9b7f-63efbd21c9a3\") " pod="kube-system/kube-proxy-fpg57"
Jul 07 15:47:26 minikube kubelet[2414]: I0707 15:47:26.048400    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-nbb46\" (UniqueName: \"kubernetes.io/projected/648a91c9-72e3-4522-9b7f-63efbd21c9a3-kube-api-access-nbb46\") pod \"kube-proxy-fpg57\" (UID: \"648a91c9-72e3-4522-9b7f-63efbd21c9a3\") " pod="kube-system/kube-proxy-fpg57"
Jul 07 15:47:26 minikube kubelet[2414]: I0707 15:47:26.146006    2414 topology_manager.go:215] "Topology Admit Handler" podUID="d588d4b4-0dd9-4ef6-869d-853baa698124" podNamespace="kube-system" podName="coredns-7db6d8ff4d-fcxg5"
Jul 07 15:47:26 minikube kubelet[2414]: I0707 15:47:26.250382    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-vk8dt\" (UniqueName: \"kubernetes.io/projected/d588d4b4-0dd9-4ef6-869d-853baa698124-kube-api-access-vk8dt\") pod \"coredns-7db6d8ff4d-fcxg5\" (UID: \"d588d4b4-0dd9-4ef6-869d-853baa698124\") " pod="kube-system/coredns-7db6d8ff4d-fcxg5"
Jul 07 15:47:26 minikube kubelet[2414]: I0707 15:47:26.250505    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/d588d4b4-0dd9-4ef6-869d-853baa698124-config-volume\") pod \"coredns-7db6d8ff4d-fcxg5\" (UID: \"d588d4b4-0dd9-4ef6-869d-853baa698124\") " pod="kube-system/coredns-7db6d8ff4d-fcxg5"
Jul 07 15:47:26 minikube kubelet[2414]: I0707 15:47:26.258285    2414 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="78a93625c52cb225eb111d8bfce61349d589324b8d9edd6383fe6a4380b767c7"
Jul 07 15:47:27 minikube kubelet[2414]: I0707 15:47:27.646697    2414 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/storage-provisioner" podStartSLOduration=11.646656419 podStartE2EDuration="11.646656419s" podCreationTimestamp="2024-07-07 15:47:16 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2024-07-07 15:47:27.64661246 +0000 UTC m=+15.245200261" watchObservedRunningTime="2024-07-07 15:47:27.646656419 +0000 UTC m=+15.245244210"
Jul 07 15:47:27 minikube kubelet[2414]: I0707 15:47:27.825728    2414 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="d2b6c080126a7f54363ef832b580c71b7d94cff9a707dc880ba2b5638c305c49"
Jul 07 15:47:28 minikube kubelet[2414]: I0707 15:47:28.890549    2414 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/coredns-7db6d8ff4d-fcxg5" podStartSLOduration=2.890516818 podStartE2EDuration="2.890516818s" podCreationTimestamp="2024-07-07 15:47:26 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2024-07-07 15:47:28.890452962 +0000 UTC m=+16.489040753" watchObservedRunningTime="2024-07-07 15:47:28.890516818 +0000 UTC m=+16.489104599"
Jul 07 15:47:28 minikube kubelet[2414]: I0707 15:47:28.937329    2414 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/kube-proxy-fpg57" podStartSLOduration=3.937303952 podStartE2EDuration="3.937303952s" podCreationTimestamp="2024-07-07 15:47:25 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2024-07-07 15:47:28.937031139 +0000 UTC m=+16.535618930" watchObservedRunningTime="2024-07-07 15:47:28.937303952 +0000 UTC m=+16.535891723"
Jul 07 15:47:33 minikube kubelet[2414]: I0707 15:47:33.588597    2414 kuberuntime_manager.go:1523] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Jul 07 15:47:33 minikube kubelet[2414]: I0707 15:47:33.599289    2414 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Jul 07 15:48:01 minikube kubelet[2414]: I0707 15:48:01.351977    2414 topology_manager.go:215] "Topology Admit Handler" podUID="d2ee9eea-5907-4e9c-a3a7-9d45250ecf11" podNamespace="default" podName="sketchborad-deployment-88cf4c55b-57kjb"
Jul 07 15:48:01 minikube kubelet[2414]: I0707 15:48:01.523040    2414 reconciler_common.go:247] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-h7pqn\" (UniqueName: \"kubernetes.io/projected/d2ee9eea-5907-4e9c-a3a7-9d45250ecf11-kube-api-access-h7pqn\") pod \"sketchborad-deployment-88cf4c55b-57kjb\" (UID: \"d2ee9eea-5907-4e9c-a3a7-9d45250ecf11\") " pod="default/sketchborad-deployment-88cf4c55b-57kjb"
Jul 07 15:48:02 minikube kubelet[2414]: I0707 15:48:02.753087    2414 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="40d5b3fcb0f35f957e4319c42d2a56f753b34c4e74b99f06942dd14edadb3c86"


==> storage-provisioner [b98938001a3e] <==
I0707 15:47:26.649246       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0707 15:47:29.790572       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0707 15:47:29.790924       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0707 15:47:29.811321       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0707 15:47:29.811509       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"359fda3b-9315-4c3b-a8a6-70c7964bab12", APIVersion:"v1", ResourceVersion:"421", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_e26c4e29-f1a9-4479-8f71-ca69fcc08b12 became leader
I0707 15:47:29.811653       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_e26c4e29-f1a9-4479-8f71-ca69fcc08b12!
I0707 15:47:29.912685       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_e26c4e29-f1a9-4479-8f71-ca69fcc08b12!

